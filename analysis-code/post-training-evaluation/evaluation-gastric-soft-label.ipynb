{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "# %connect_info\n",
    "%qtconsole"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "end_time": "2023-10-05T04:51:22.131970Z",
     "start_time": "2023-10-05T04:51:21.797768Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from graphgym.custom_graphgym.loader.protein import ProteinDataset\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-07T16:22:38.891284Z",
     "start_time": "2023-10-07T16:22:38.772441Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "outputs": [],
   "source": [
    "os.chdir('/Users/cgu3/Documents/Grape-Pi')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-07T16:22:38.922370Z",
     "start_time": "2023-10-07T16:22:38.873694Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Import data from csv fies"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "outputs": [],
   "source": [
    "\n",
    "# dataset = ProteinDataset(\"data/yeast-ORBI\", numeric_columns=['protein probability'], label_column=None)\n",
    "# dataset = ProteinBatchDataset(\"data/yeast-LCQ\", numeric_params=['protein probability'])\n",
    "# dataset = ProteinBatchDataset(\"data/yeast-ORBI-mRNA\", numeric_params=['protein probability', 'mRNA(M)'])\n",
    "# dataset = ProteinBatchDataset(\"data/yeast-LCQ-mRNA\", numeric_params=['protein probability', 'mRNA(M)'])\n",
    "# dataset = ProteinDataset(\"data/single-soft-label\", numeric_columns=['protein_probability', 'mRNA_TPM'], label_column=None)\n",
    "dataset = ProteinDataset(\"data/single\", numeric_columns=['protein_probability'], label_column=None)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-07T16:41:00.251925Z",
     "start_time": "2023-10-07T16:41:00.163145Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data/single-soft-label/raw/protein/data_train_with_soft_label.csv'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[190], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m df \u001B[38;5;241m=\u001B[39m \u001B[43mpd\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mread_csv\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mdata/single-soft-label/raw/protein/data_train_with_soft_label.csv\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m      2\u001B[0m \u001B[38;5;66;03m# df = pd.read_csv('/Users/cgu3/Documents/data/SG_combined_protein_0982_with_protein_probability.csv')\u001B[39;00m\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/Grape-Pi/lib/python3.10/site-packages/pandas/io/parsers/readers.py:912\u001B[0m, in \u001B[0;36mread_csv\u001B[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001B[0m\n\u001B[1;32m    899\u001B[0m kwds_defaults \u001B[38;5;241m=\u001B[39m _refine_defaults_read(\n\u001B[1;32m    900\u001B[0m     dialect,\n\u001B[1;32m    901\u001B[0m     delimiter,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    908\u001B[0m     dtype_backend\u001B[38;5;241m=\u001B[39mdtype_backend,\n\u001B[1;32m    909\u001B[0m )\n\u001B[1;32m    910\u001B[0m kwds\u001B[38;5;241m.\u001B[39mupdate(kwds_defaults)\n\u001B[0;32m--> 912\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_read\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfilepath_or_buffer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwds\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/Grape-Pi/lib/python3.10/site-packages/pandas/io/parsers/readers.py:577\u001B[0m, in \u001B[0;36m_read\u001B[0;34m(filepath_or_buffer, kwds)\u001B[0m\n\u001B[1;32m    574\u001B[0m _validate_names(kwds\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnames\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m))\n\u001B[1;32m    576\u001B[0m \u001B[38;5;66;03m# Create the parser.\u001B[39;00m\n\u001B[0;32m--> 577\u001B[0m parser \u001B[38;5;241m=\u001B[39m \u001B[43mTextFileReader\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfilepath_or_buffer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwds\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    579\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m chunksize \u001B[38;5;129;01mor\u001B[39;00m iterator:\n\u001B[1;32m    580\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m parser\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/Grape-Pi/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1407\u001B[0m, in \u001B[0;36mTextFileReader.__init__\u001B[0;34m(self, f, engine, **kwds)\u001B[0m\n\u001B[1;32m   1404\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39moptions[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mhas_index_names\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m kwds[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mhas_index_names\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n\u001B[1;32m   1406\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhandles: IOHandles \u001B[38;5;241m|\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m-> 1407\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_engine \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_make_engine\u001B[49m\u001B[43m(\u001B[49m\u001B[43mf\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mengine\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/Grape-Pi/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1661\u001B[0m, in \u001B[0;36mTextFileReader._make_engine\u001B[0;34m(self, f, engine)\u001B[0m\n\u001B[1;32m   1659\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mb\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m mode:\n\u001B[1;32m   1660\u001B[0m         mode \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mb\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m-> 1661\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhandles \u001B[38;5;241m=\u001B[39m \u001B[43mget_handle\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1662\u001B[0m \u001B[43m    \u001B[49m\u001B[43mf\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1663\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmode\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1664\u001B[0m \u001B[43m    \u001B[49m\u001B[43mencoding\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mencoding\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1665\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcompression\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mcompression\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1666\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmemory_map\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mmemory_map\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1667\u001B[0m \u001B[43m    \u001B[49m\u001B[43mis_text\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mis_text\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1668\u001B[0m \u001B[43m    \u001B[49m\u001B[43merrors\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mencoding_errors\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mstrict\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1669\u001B[0m \u001B[43m    \u001B[49m\u001B[43mstorage_options\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mstorage_options\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1670\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1671\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhandles \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m   1672\u001B[0m f \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhandles\u001B[38;5;241m.\u001B[39mhandle\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/Grape-Pi/lib/python3.10/site-packages/pandas/io/common.py:859\u001B[0m, in \u001B[0;36mget_handle\u001B[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001B[0m\n\u001B[1;32m    854\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(handle, \u001B[38;5;28mstr\u001B[39m):\n\u001B[1;32m    855\u001B[0m     \u001B[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001B[39;00m\n\u001B[1;32m    856\u001B[0m     \u001B[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001B[39;00m\n\u001B[1;32m    857\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m ioargs\u001B[38;5;241m.\u001B[39mencoding \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mb\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m ioargs\u001B[38;5;241m.\u001B[39mmode:\n\u001B[1;32m    858\u001B[0m         \u001B[38;5;66;03m# Encoding\u001B[39;00m\n\u001B[0;32m--> 859\u001B[0m         handle \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mopen\u001B[39;49m\u001B[43m(\u001B[49m\n\u001B[1;32m    860\u001B[0m \u001B[43m            \u001B[49m\u001B[43mhandle\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    861\u001B[0m \u001B[43m            \u001B[49m\u001B[43mioargs\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmode\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    862\u001B[0m \u001B[43m            \u001B[49m\u001B[43mencoding\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mioargs\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mencoding\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    863\u001B[0m \u001B[43m            \u001B[49m\u001B[43merrors\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43merrors\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    864\u001B[0m \u001B[43m            \u001B[49m\u001B[43mnewline\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m    865\u001B[0m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    866\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    867\u001B[0m         \u001B[38;5;66;03m# Binary mode\u001B[39;00m\n\u001B[1;32m    868\u001B[0m         handle \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mopen\u001B[39m(handle, ioargs\u001B[38;5;241m.\u001B[39mmode)\n",
      "\u001B[0;31mFileNotFoundError\u001B[0m: [Errno 2] No such file or directory: 'data/single-soft-label/raw/protein/data_train_with_soft_label.csv'"
     ]
    }
   ],
   "source": [
    "\n",
    "df = pd.read_csv('data/single-soft-label/raw/protein/data_train_with_soft_label.csv')\n",
    "# df = pd.read_csv('/Users/cgu3/Documents/data/SG_combined_protein_0982_with_protein_probability.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-07T16:22:41.541555Z",
     "start_time": "2023-10-07T16:22:40.785301Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, data, labels, ids, train_mask=None, val_mask=None, test_mask=None):\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "        self.ids = ids\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        sample_data = self.data[index]\n",
    "        sample_label = self.labels[index]\n",
    "        sample_id = self.ids[index].tolist()\n",
    "        return sample_data, sample_label, sample_id\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-06T15:33:32.598501Z",
     "start_time": "2023-10-06T15:33:32.581962Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "outputs": [],
   "source": [
    "x = torch.tensor(df.loc[:, ['protein_probability']].values, dtype=torch.float)\n",
    "# x = torch.tensor(df.loc[:, ['protein_probability', 'mRNA_TPM']].values, dtype=torch.float)\n",
    "y = torch.tensor(df.loc[:, ['protein_probability_soft_label']].values, dtype=torch.float)\n",
    "ids = df.loc[:, ['protein.Accession']].values"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-05T21:39:44.692867Z",
     "start_time": "2023-10-05T21:39:44.673987Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 2 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.subplot(3, 1, 1)\n",
    "plt.hist(x[:, 0], bins=100);\n",
    "plt.title('protein_probability');\n",
    "# \n",
    "# plt.subplot(3, 1, 2)\n",
    "# plt.hist(x[:, 1], bins=100);\n",
    "# plt.title('mRNA_TPM');\n",
    "\n",
    "plt.subplot(3, 1, 3)\n",
    "plt.hist(y.squeeze(-1), bins=100);\n",
    "plt.title('soft_label');"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-05T21:39:46.320984Z",
     "start_time": "2023-10-05T21:39:45.110789Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rebuilding...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "protein_dataset = ProteinDataset(\"data/single\", numeric_columns=['protein_probability'], label_column='hard_label', rebuild=True)\n",
    "# protein_dataset = ProteinDataset(\"data/yeast-ORBI\", numeric_columns=['protein_probability'], label_column=None, rebuild=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-07T16:41:12.730397Z",
     "start_time": "2023-10-07T16:41:11.005633Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, Subset\n",
    "dataset = CustomDataset(protein_dataset.x, protein_dataset.y, ids)\n",
    "\n",
    "train_indices = torch.nonzero(protein_dataset.train_mask).squeeze().tolist()\n",
    "train_dataset = Subset(dataset, train_indices)\n",
    "\n",
    "val_indices = torch.nonzero(protein_dataset.val_mask).squeeze().tolist()\n",
    "val_dataset = Subset(dataset, val_indices)\n",
    "\n",
    "test_indices = torch.nonzero(protein_dataset.test_mask).squeeze().tolist()\n",
    "test_dataset = Subset(dataset, test_indices)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-07T16:41:12.763299Z",
     "start_time": "2023-10-07T16:41:12.745969Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=64, shuffle=False)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=64, shuffle=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-07T16:41:12.791367Z",
     "start_time": "2023-10-07T16:41:12.769493Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "outputs": [],
   "source": [
    "import os\n",
    "from torch import optim, nn, utils, Tensor\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision.transforms import ToTensor\n",
    "import pytorch_lightning as pl\n",
    "from torchmetrics.classification import BinaryAUROC, BinaryAccuracy, BinaryF1Score\n",
    "\n",
    "\n",
    "# define the LightningModule\n",
    "class MLP(pl.LightningModule):\n",
    "    def __init__(self, num_features, hidden_channels, num_classes, criterion):\n",
    "        super().__init__()\n",
    "        torch.manual_seed(12345)\n",
    "        self.lin1 = nn.Linear(num_features, hidden_channels)\n",
    "        self.lin2 = nn.Linear(hidden_channels, num_classes)\n",
    "        # self.lin3 = nn.Linear(hidden_channels, num_classes)\n",
    "        self.criterion = criterion\n",
    "        self.val_auroc = BinaryAUROC()\n",
    "        self.test_auroc = BinaryAUROC()\n",
    "        self.val_accuracy = BinaryAccuracy()\n",
    "        self.test_accuracy = BinaryAccuracy()\n",
    "        self.val_F1 = BinaryF1Score()\n",
    "        self.test_F1 = BinaryF1Score()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.lin1(x)\n",
    "        x = x.relu()\n",
    "        x = self.lin2(x)\n",
    "        # x = x.relu()\n",
    "        # x = self.lin3(x)\n",
    "        return x\n",
    "\n",
    "    def get_auc(self, out, target):\n",
    "        return self.auroc(out, target)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y, id = batch\n",
    "        logits = self(x).squeeze(-1)  # Perform a single forward pass.\n",
    "\n",
    "        loss = self.criterion(logits, y)  # Compute the loss solely based on the training nodes.\n",
    "        values = {\"loss\": loss}\n",
    "        self.log_dict(values, prog_bar=True)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y, ids = batch\n",
    "        logits = self(x).squeeze(-1)  # Perform a single forward pass.\n",
    "        y = torch.where(y > 0.95, 1.0, 0.0)\n",
    "        self.val_accuracy.update(logits, y)\n",
    "        loss = self.criterion(logits, y)  # Compute the loss solely based on the training nodes.\n",
    "        self.val_auroc.update(logits, y)\n",
    "        self.val_F1.update(logits, y)\n",
    "        values = {\"val_loss\": loss, \"val_acc\": self.val_accuracy, \"val_auroc\": self.val_auroc, \"val_F1\": self.val_F1}\n",
    "        self.log_dict(values, prog_bar=True, on_step=False, on_epoch=True)\n",
    "        return loss\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        x, y, ids = batch\n",
    "        logits = self(x).squeeze(-1)\n",
    "        y = torch.where(y > 0.95, 1.0, 0.0)\n",
    "        self.test_accuracy.update(logits, y)\n",
    "        loss = self.criterion(logits, y)\n",
    "        self.test_auroc.update(logits, y)\n",
    "        self.test_F1.update(logits, y)\n",
    "        values = {\"test_loss\": loss, \"test_acc\": self.test_accuracy, \"test_auroc\": self.test_auroc, \"test_F1\": self.test_F1}\n",
    "        self.log_dict(values, prog_bar=True, on_step=False, on_epoch=True)\n",
    "        return loss\n",
    "    \n",
    "    def predict_step(self, batch, batch_idx):\n",
    "        x, y, ids = batch\n",
    "        ids = [item for sublist in ids for item in sublist]\n",
    "        logits = self(x).squeeze(-1)\n",
    "        pred_prob = torch.nn.functional.sigmoid(logits)\n",
    "        return (ids, x[:, 0], x[:, 1], pred_prob, y)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = optim.Adam(self.parameters(), lr=1e-3)\n",
    "        return optimizer\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-07T16:41:12.838125Z",
     "start_time": "2023-10-07T16:41:12.833734Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "outputs": [],
   "source": [
    "# init the autoencoder\n",
    "MLP_model = MLP(1, 1, 1, criterion = torch.nn.BCEWithLogitsLoss())\n",
    "# MLP_model = MLP(dataset.num_node_features, 10, 2, criterion = torch.nn.CrossEntropyLoss())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-07T16:41:13.132064Z",
     "start_time": "2023-10-07T16:41:13.099859Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "outputs": [],
   "source": [
    "import sys\n",
    "from pytorch_lightning.callbacks import TQDMProgressBar\n",
    "\n",
    "\n",
    "class MyProgressBar(TQDMProgressBar):\n",
    "    def init_validation_tqdm(self):\n",
    "        bar = super().init_validation_tqdm()\n",
    "        if not sys.stdout.isatty():\n",
    "            bar.disable = True\n",
    "        return bar\n",
    "\n",
    "    def init_predict_tqdm(self):\n",
    "        bar = super().init_predict_tqdm()\n",
    "        if not sys.stdout.isatty():\n",
    "            bar.disable = True\n",
    "        return bar\n",
    "\n",
    "    def init_test_tqdm(self):\n",
    "        bar = super().init_test_tqdm()\n",
    "        if not sys.stdout.isatty():\n",
    "            bar.disable = True\n",
    "        return bar\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-07T16:41:13.326364Z",
     "start_time": "2023-10-07T16:41:13.315606Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "trainer = pl.Trainer(limit_train_batches=100, max_epochs=100, callbacks=[MyProgressBar()])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-07T16:41:13.648873Z",
     "start_time": "2023-10-07T16:41:13.519931Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name          | Type              | Params\n",
      "----------------------------------------------------\n",
      "0 | lin1          | Linear            | 2     \n",
      "1 | lin2          | Linear            | 2     \n",
      "2 | criterion     | BCEWithLogitsLoss | 0     \n",
      "3 | val_auroc     | BinaryAUROC       | 0     \n",
      "4 | test_auroc    | BinaryAUROC       | 0     \n",
      "5 | val_accuracy  | BinaryAccuracy    | 0     \n",
      "6 | test_accuracy | BinaryAccuracy    | 0     \n",
      "7 | val_F1        | BinaryF1Score     | 0     \n",
      "8 | test_F1       | BinaryF1Score     | 0     \n",
      "----------------------------------------------------\n",
      "4         Trainable params\n",
      "0         Non-trainable params\n",
      "4         Total params\n",
      "0.000     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                           "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/cgu3/opt/anaconda3/envs/Grape-Pi/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:438: PossibleUserWarning: The dataloader, val_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "/Users/cgu3/opt/anaconda3/envs/Grape-Pi/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:438: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 100/100 [00:00<00:00, 148.97it/s, v_num=41, loss=0.566]\n",
      "Epoch 1: 100%|██████████| 100/100 [00:00<00:00, 145.07it/s, v_num=41, loss=0.631, val_loss=0.644, val_acc=0.699, val_auroc=0.789, val_F1=0.732]\n",
      "Epoch 2: 100%|██████████| 100/100 [00:00<00:00, 155.91it/s, v_num=41, loss=0.657, val_loss=0.622, val_acc=0.699, val_auroc=0.789, val_F1=0.732]\n",
      "Epoch 3: 100%|██████████| 100/100 [00:00<00:00, 153.20it/s, v_num=41, loss=0.629, val_loss=0.607, val_acc=0.699, val_auroc=0.789, val_F1=0.732]\n",
      "Epoch 4: 100%|██████████| 100/100 [00:00<00:00, 150.94it/s, v_num=41, loss=0.540, val_loss=0.594, val_acc=0.699, val_auroc=0.789, val_F1=0.732]\n",
      "Epoch 5: 100%|██████████| 100/100 [00:00<00:00, 148.30it/s, v_num=41, loss=0.589, val_loss=0.582, val_acc=0.700, val_auroc=0.786, val_F1=0.726]\n",
      "Epoch 6: 100%|██████████| 100/100 [00:00<00:00, 158.24it/s, v_num=41, loss=0.526, val_loss=0.571, val_acc=0.700, val_auroc=0.786, val_F1=0.726]\n",
      "Epoch 7: 100%|██████████| 100/100 [00:00<00:00, 151.36it/s, v_num=41, loss=0.567, val_loss=0.560, val_acc=0.700, val_auroc=0.786, val_F1=0.726]\n",
      "Epoch 8: 100%|██████████| 100/100 [00:00<00:00, 178.12it/s, v_num=41, loss=0.458, val_loss=0.550, val_acc=0.700, val_auroc=0.786, val_F1=0.726]\n",
      "Epoch 9: 100%|██████████| 100/100 [00:00<00:00, 166.65it/s, v_num=41, loss=0.509, val_loss=0.542, val_acc=0.713, val_auroc=0.786, val_F1=0.727]\n",
      "Epoch 10: 100%|██████████| 100/100 [00:00<00:00, 150.55it/s, v_num=41, loss=0.519, val_loss=0.536, val_acc=0.712, val_auroc=0.786, val_F1=0.723]\n",
      "Epoch 11: 100%|██████████| 100/100 [00:00<00:00, 157.65it/s, v_num=41, loss=0.516, val_loss=0.530, val_acc=0.718, val_auroc=0.786, val_F1=0.723]\n",
      "Epoch 12: 100%|██████████| 100/100 [00:00<00:00, 160.11it/s, v_num=41, loss=0.581, val_loss=0.527, val_acc=0.718, val_auroc=0.786, val_F1=0.723]\n",
      "Epoch 13: 100%|██████████| 100/100 [00:00<00:00, 151.63it/s, v_num=41, loss=0.477, val_loss=0.524, val_acc=0.718, val_auroc=0.786, val_F1=0.721]\n",
      "Epoch 14: 100%|██████████| 100/100 [00:00<00:00, 156.84it/s, v_num=41, loss=0.519, val_loss=0.522, val_acc=0.718, val_auroc=0.786, val_F1=0.720]\n",
      "Epoch 15: 100%|██████████| 100/100 [00:00<00:00, 155.91it/s, v_num=41, loss=0.449, val_loss=0.521, val_acc=0.717, val_auroc=0.786, val_F1=0.719]\n",
      "Epoch 16: 100%|██████████| 100/100 [00:00<00:00, 160.02it/s, v_num=41, loss=0.512, val_loss=0.520, val_acc=0.717, val_auroc=0.786, val_F1=0.718]\n",
      "Epoch 17: 100%|██████████| 100/100 [00:00<00:00, 155.39it/s, v_num=41, loss=0.533, val_loss=0.519, val_acc=0.717, val_auroc=0.786, val_F1=0.718]\n",
      "Epoch 18: 100%|██████████| 100/100 [00:00<00:00, 155.30it/s, v_num=41, loss=0.515, val_loss=0.519, val_acc=0.717, val_auroc=0.786, val_F1=0.718]\n",
      "Epoch 19: 100%|██████████| 100/100 [00:00<00:00, 169.75it/s, v_num=41, loss=0.553, val_loss=0.519, val_acc=0.716, val_auroc=0.786, val_F1=0.717]\n",
      "Epoch 20: 100%|██████████| 100/100 [00:00<00:00, 160.13it/s, v_num=41, loss=0.515, val_loss=0.519, val_acc=0.718, val_auroc=0.786, val_F1=0.719]\n",
      "Epoch 21: 100%|██████████| 100/100 [00:00<00:00, 152.80it/s, v_num=41, loss=0.459, val_loss=0.518, val_acc=0.721, val_auroc=0.786, val_F1=0.721]\n",
      "Epoch 22: 100%|██████████| 100/100 [00:00<00:00, 155.36it/s, v_num=41, loss=0.514, val_loss=0.517, val_acc=0.727, val_auroc=0.786, val_F1=0.724]\n",
      "Epoch 23: 100%|██████████| 100/100 [00:00<00:00, 161.13it/s, v_num=41, loss=0.500, val_loss=0.517, val_acc=0.727, val_auroc=0.786, val_F1=0.724]\n",
      "Epoch 24: 100%|██████████| 100/100 [00:00<00:00, 158.74it/s, v_num=41, loss=0.491, val_loss=0.516, val_acc=0.727, val_auroc=0.786, val_F1=0.723]\n",
      "Epoch 25: 100%|██████████| 100/100 [00:00<00:00, 156.94it/s, v_num=41, loss=0.471, val_loss=0.516, val_acc=0.728, val_auroc=0.786, val_F1=0.724]\n",
      "Epoch 26: 100%|██████████| 100/100 [00:00<00:00, 158.27it/s, v_num=41, loss=0.515, val_loss=0.515, val_acc=0.727, val_auroc=0.786, val_F1=0.721]\n",
      "Epoch 27: 100%|██████████| 100/100 [00:00<00:00, 156.03it/s, v_num=41, loss=0.479, val_loss=0.515, val_acc=0.727, val_auroc=0.786, val_F1=0.721]\n",
      "Epoch 28: 100%|██████████| 100/100 [00:00<00:00, 138.30it/s, v_num=41, loss=0.479, val_loss=0.515, val_acc=0.727, val_auroc=0.786, val_F1=0.721]\n",
      "Epoch 29: 100%|██████████| 100/100 [00:00<00:00, 153.58it/s, v_num=41, loss=0.455, val_loss=0.515, val_acc=0.726, val_auroc=0.786, val_F1=0.719]\n",
      "Epoch 30: 100%|██████████| 100/100 [00:00<00:00, 158.52it/s, v_num=41, loss=0.450, val_loss=0.514, val_acc=0.726, val_auroc=0.786, val_F1=0.718]\n",
      "Epoch 31: 100%|██████████| 100/100 [00:00<00:00, 156.59it/s, v_num=41, loss=0.473, val_loss=0.514, val_acc=0.728, val_auroc=0.786, val_F1=0.718]\n",
      "Epoch 32: 100%|██████████| 100/100 [00:00<00:00, 155.68it/s, v_num=41, loss=0.449, val_loss=0.514, val_acc=0.730, val_auroc=0.786, val_F1=0.720]\n",
      "Epoch 33: 100%|██████████| 100/100 [00:00<00:00, 157.49it/s, v_num=41, loss=0.599, val_loss=0.514, val_acc=0.729, val_auroc=0.786, val_F1=0.719]\n",
      "Epoch 34: 100%|██████████| 100/100 [00:00<00:00, 158.86it/s, v_num=41, loss=0.544, val_loss=0.513, val_acc=0.728, val_auroc=0.786, val_F1=0.717]\n",
      "Epoch 35: 100%|██████████| 100/100 [00:00<00:00, 140.17it/s, v_num=41, loss=0.473, val_loss=0.514, val_acc=0.729, val_auroc=0.786, val_F1=0.719]\n",
      "Epoch 36: 100%|██████████| 100/100 [00:00<00:00, 134.97it/s, v_num=41, loss=0.429, val_loss=0.513, val_acc=0.727, val_auroc=0.786, val_F1=0.716]\n",
      "Epoch 37: 100%|██████████| 100/100 [00:00<00:00, 155.40it/s, v_num=41, loss=0.425, val_loss=0.513, val_acc=0.725, val_auroc=0.786, val_F1=0.713]\n",
      "Epoch 38: 100%|██████████| 100/100 [00:00<00:00, 158.97it/s, v_num=41, loss=0.521, val_loss=0.512, val_acc=0.727, val_auroc=0.786, val_F1=0.715]\n",
      "Epoch 39: 100%|██████████| 100/100 [00:00<00:00, 155.48it/s, v_num=41, loss=0.514, val_loss=0.513, val_acc=0.727, val_auroc=0.786, val_F1=0.715]\n",
      "Epoch 40: 100%|██████████| 100/100 [00:00<00:00, 154.52it/s, v_num=41, loss=0.496, val_loss=0.513, val_acc=0.726, val_auroc=0.786, val_F1=0.713]\n",
      "Epoch 41: 100%|██████████| 100/100 [00:00<00:00, 157.88it/s, v_num=41, loss=0.466, val_loss=0.513, val_acc=0.727, val_auroc=0.789, val_F1=0.715]\n",
      "Epoch 42: 100%|██████████| 100/100 [00:00<00:00, 141.09it/s, v_num=41, loss=0.462, val_loss=0.513, val_acc=0.727, val_auroc=0.788, val_F1=0.715]\n",
      "Epoch 43: 100%|██████████| 100/100 [00:00<00:00, 156.24it/s, v_num=41, loss=0.418, val_loss=0.513, val_acc=0.727, val_auroc=0.788, val_F1=0.715]\n",
      "Epoch 44: 100%|██████████| 100/100 [00:00<00:00, 156.79it/s, v_num=41, loss=0.529, val_loss=0.513, val_acc=0.727, val_auroc=0.786, val_F1=0.714]\n",
      "Epoch 45: 100%|██████████| 100/100 [00:00<00:00, 159.07it/s, v_num=41, loss=0.513, val_loss=0.512, val_acc=0.728, val_auroc=0.785, val_F1=0.715]\n",
      "Epoch 46: 100%|██████████| 100/100 [00:00<00:00, 160.81it/s, v_num=41, loss=0.464, val_loss=0.513, val_acc=0.727, val_auroc=0.785, val_F1=0.714]\n",
      "Epoch 47: 100%|██████████| 100/100 [00:00<00:00, 158.44it/s, v_num=41, loss=0.546, val_loss=0.512, val_acc=0.728, val_auroc=0.783, val_F1=0.714]\n",
      "Epoch 48: 100%|██████████| 100/100 [00:00<00:00, 154.60it/s, v_num=41, loss=0.468, val_loss=0.512, val_acc=0.730, val_auroc=0.782, val_F1=0.716]\n",
      "Epoch 49: 100%|██████████| 100/100 [00:00<00:00, 150.87it/s, v_num=41, loss=0.498, val_loss=0.512, val_acc=0.731, val_auroc=0.782, val_F1=0.716]\n",
      "Epoch 50: 100%|██████████| 100/100 [00:00<00:00, 155.86it/s, v_num=41, loss=0.526, val_loss=0.512, val_acc=0.731, val_auroc=0.782, val_F1=0.716]\n",
      "Epoch 51: 100%|██████████| 100/100 [00:00<00:00, 153.38it/s, v_num=41, loss=0.452, val_loss=0.512, val_acc=0.731, val_auroc=0.783, val_F1=0.716]\n",
      "Epoch 52: 100%|██████████| 100/100 [00:00<00:00, 172.41it/s, v_num=41, loss=0.527, val_loss=0.512, val_acc=0.731, val_auroc=0.783, val_F1=0.716]\n",
      "Epoch 53: 100%|██████████| 100/100 [00:00<00:00, 164.52it/s, v_num=41, loss=0.480, val_loss=0.512, val_acc=0.731, val_auroc=0.783, val_F1=0.716]\n",
      "Epoch 54: 100%|██████████| 100/100 [00:00<00:00, 152.99it/s, v_num=41, loss=0.553, val_loss=0.512, val_acc=0.731, val_auroc=0.783, val_F1=0.716]\n",
      "Epoch 55: 100%|██████████| 100/100 [00:00<00:00, 153.14it/s, v_num=41, loss=0.491, val_loss=0.512, val_acc=0.732, val_auroc=0.783, val_F1=0.717]\n",
      "Epoch 56: 100%|██████████| 100/100 [00:00<00:00, 152.19it/s, v_num=41, loss=0.535, val_loss=0.511, val_acc=0.730, val_auroc=0.783, val_F1=0.714]\n",
      "Epoch 57: 100%|██████████| 100/100 [00:00<00:00, 149.01it/s, v_num=41, loss=0.497, val_loss=0.511, val_acc=0.732, val_auroc=0.784, val_F1=0.716]\n",
      "Epoch 58: 100%|██████████| 100/100 [00:00<00:00, 145.30it/s, v_num=41, loss=0.502, val_loss=0.511, val_acc=0.731, val_auroc=0.782, val_F1=0.714]\n",
      "Epoch 59: 100%|██████████| 100/100 [00:00<00:00, 150.99it/s, v_num=41, loss=0.518, val_loss=0.511, val_acc=0.731, val_auroc=0.782, val_F1=0.714]\n",
      "Epoch 60: 100%|██████████| 100/100 [00:00<00:00, 153.76it/s, v_num=41, loss=0.567, val_loss=0.511, val_acc=0.731, val_auroc=0.782, val_F1=0.713]\n",
      "Epoch 61: 100%|██████████| 100/100 [00:00<00:00, 149.47it/s, v_num=41, loss=0.537, val_loss=0.511, val_acc=0.731, val_auroc=0.782, val_F1=0.713]\n",
      "Epoch 62: 100%|██████████| 100/100 [00:00<00:00, 154.83it/s, v_num=41, loss=0.471, val_loss=0.511, val_acc=0.731, val_auroc=0.782, val_F1=0.714]\n",
      "Epoch 63: 100%|██████████| 100/100 [00:00<00:00, 152.61it/s, v_num=41, loss=0.502, val_loss=0.512, val_acc=0.732, val_auroc=0.782, val_F1=0.716]\n",
      "Epoch 64: 100%|██████████| 100/100 [00:00<00:00, 153.81it/s, v_num=41, loss=0.590, val_loss=0.511, val_acc=0.731, val_auroc=0.781, val_F1=0.713]\n",
      "Epoch 65: 100%|██████████| 100/100 [00:00<00:00, 155.73it/s, v_num=41, loss=0.500, val_loss=0.511, val_acc=0.731, val_auroc=0.780, val_F1=0.713]\n",
      "Epoch 66: 100%|██████████| 100/100 [00:00<00:00, 156.93it/s, v_num=41, loss=0.471, val_loss=0.511, val_acc=0.731, val_auroc=0.779, val_F1=0.713]\n",
      "Epoch 67: 100%|██████████| 100/100 [00:00<00:00, 160.55it/s, v_num=41, loss=0.451, val_loss=0.510, val_acc=0.730, val_auroc=0.779, val_F1=0.711]\n",
      "Epoch 68: 100%|██████████| 100/100 [00:00<00:00, 155.87it/s, v_num=41, loss=0.500, val_loss=0.511, val_acc=0.732, val_auroc=0.779, val_F1=0.714]\n",
      "Epoch 69: 100%|██████████| 100/100 [00:00<00:00, 136.54it/s, v_num=41, loss=0.445, val_loss=0.511, val_acc=0.731, val_auroc=0.779, val_F1=0.713]\n",
      "Epoch 70: 100%|██████████| 100/100 [00:00<00:00, 140.85it/s, v_num=41, loss=0.482, val_loss=0.511, val_acc=0.732, val_auroc=0.779, val_F1=0.714]\n",
      "Epoch 71: 100%|██████████| 100/100 [00:00<00:00, 153.61it/s, v_num=41, loss=0.516, val_loss=0.511, val_acc=0.730, val_auroc=0.779, val_F1=0.712]\n",
      "Epoch 72: 100%|██████████| 100/100 [00:00<00:00, 157.19it/s, v_num=41, loss=0.475, val_loss=0.511, val_acc=0.731, val_auroc=0.779, val_F1=0.713]\n",
      "Epoch 73: 100%|██████████| 100/100 [00:00<00:00, 155.19it/s, v_num=41, loss=0.509, val_loss=0.511, val_acc=0.731, val_auroc=0.779, val_F1=0.713]\n",
      "Epoch 74: 100%|██████████| 100/100 [00:00<00:00, 158.66it/s, v_num=41, loss=0.493, val_loss=0.511, val_acc=0.730, val_auroc=0.779, val_F1=0.712]\n",
      "Epoch 75: 100%|██████████| 100/100 [00:00<00:00, 157.52it/s, v_num=41, loss=0.531, val_loss=0.511, val_acc=0.730, val_auroc=0.779, val_F1=0.712]\n",
      "Epoch 76: 100%|██████████| 100/100 [00:00<00:00, 151.90it/s, v_num=41, loss=0.464, val_loss=0.511, val_acc=0.730, val_auroc=0.778, val_F1=0.711]\n",
      "Epoch 77: 100%|██████████| 100/100 [00:00<00:00, 154.75it/s, v_num=41, loss=0.502, val_loss=0.511, val_acc=0.731, val_auroc=0.779, val_F1=0.713]\n",
      "Epoch 78: 100%|██████████| 100/100 [00:00<00:00, 152.22it/s, v_num=41, loss=0.508, val_loss=0.510, val_acc=0.730, val_auroc=0.778, val_F1=0.711]\n",
      "Epoch 79: 100%|██████████| 100/100 [00:00<00:00, 153.09it/s, v_num=41, loss=0.535, val_loss=0.510, val_acc=0.730, val_auroc=0.778, val_F1=0.711]\n",
      "Epoch 80: 100%|██████████| 100/100 [00:00<00:00, 153.66it/s, v_num=41, loss=0.478, val_loss=0.510, val_acc=0.730, val_auroc=0.777, val_F1=0.711]\n",
      "Epoch 81: 100%|██████████| 100/100 [00:00<00:00, 149.94it/s, v_num=41, loss=0.474, val_loss=0.510, val_acc=0.730, val_auroc=0.778, val_F1=0.711]\n",
      "Epoch 82: 100%|██████████| 100/100 [00:00<00:00, 153.90it/s, v_num=41, loss=0.454, val_loss=0.511, val_acc=0.730, val_auroc=0.777, val_F1=0.711]\n",
      "Epoch 83: 100%|██████████| 100/100 [00:00<00:00, 146.35it/s, v_num=41, loss=0.472, val_loss=0.511, val_acc=0.731, val_auroc=0.778, val_F1=0.713]\n",
      "Epoch 84: 100%|██████████| 100/100 [00:00<00:00, 155.76it/s, v_num=41, loss=0.544, val_loss=0.510, val_acc=0.730, val_auroc=0.777, val_F1=0.711]\n",
      "Epoch 85: 100%|██████████| 100/100 [00:00<00:00, 155.29it/s, v_num=41, loss=0.577, val_loss=0.510, val_acc=0.730, val_auroc=0.778, val_F1=0.711]\n",
      "Epoch 86: 100%|██████████| 100/100 [00:00<00:00, 162.80it/s, v_num=41, loss=0.497, val_loss=0.510, val_acc=0.730, val_auroc=0.778, val_F1=0.711]\n",
      "Epoch 87: 100%|██████████| 100/100 [00:00<00:00, 155.36it/s, v_num=41, loss=0.498, val_loss=0.510, val_acc=0.730, val_auroc=0.778, val_F1=0.711]\n",
      "Epoch 88: 100%|██████████| 100/100 [00:00<00:00, 158.83it/s, v_num=41, loss=0.507, val_loss=0.511, val_acc=0.730, val_auroc=0.777, val_F1=0.711]\n",
      "Epoch 89: 100%|██████████| 100/100 [00:00<00:00, 159.12it/s, v_num=41, loss=0.592, val_loss=0.511, val_acc=0.731, val_auroc=0.778, val_F1=0.713]\n",
      "Epoch 90: 100%|██████████| 100/100 [00:00<00:00, 157.20it/s, v_num=41, loss=0.520, val_loss=0.511, val_acc=0.730, val_auroc=0.777, val_F1=0.711]\n",
      "Epoch 91: 100%|██████████| 100/100 [00:00<00:00, 156.02it/s, v_num=41, loss=0.609, val_loss=0.510, val_acc=0.730, val_auroc=0.778, val_F1=0.711]\n",
      "Epoch 92: 100%|██████████| 100/100 [00:00<00:00, 156.23it/s, v_num=41, loss=0.513, val_loss=0.510, val_acc=0.730, val_auroc=0.778, val_F1=0.711]\n",
      "Epoch 93: 100%|██████████| 100/100 [00:00<00:00, 154.11it/s, v_num=41, loss=0.449, val_loss=0.510, val_acc=0.730, val_auroc=0.777, val_F1=0.711]\n",
      "Epoch 94: 100%|██████████| 100/100 [00:00<00:00, 173.36it/s, v_num=41, loss=0.418, val_loss=0.511, val_acc=0.730, val_auroc=0.777, val_F1=0.711]\n",
      "Epoch 95: 100%|██████████| 100/100 [00:00<00:00, 157.49it/s, v_num=41, loss=0.439, val_loss=0.510, val_acc=0.730, val_auroc=0.778, val_F1=0.711]\n",
      "Epoch 96: 100%|██████████| 100/100 [00:00<00:00, 160.00it/s, v_num=41, loss=0.633, val_loss=0.510, val_acc=0.730, val_auroc=0.778, val_F1=0.711]\n",
      "Epoch 97: 100%|██████████| 100/100 [00:00<00:00, 153.64it/s, v_num=41, loss=0.445, val_loss=0.511, val_acc=0.730, val_auroc=0.777, val_F1=0.711]\n",
      "Epoch 98: 100%|██████████| 100/100 [00:00<00:00, 152.66it/s, v_num=41, loss=0.605, val_loss=0.511, val_acc=0.730, val_auroc=0.778, val_F1=0.711]\n",
      "Epoch 99: 100%|██████████| 100/100 [00:00<00:00, 157.12it/s, v_num=41, loss=0.561, val_loss=0.511, val_acc=0.732, val_auroc=0.778, val_F1=0.714]\n",
      "Epoch 99: 100%|██████████| 100/100 [00:00<00:00, 141.04it/s, v_num=41, loss=0.561, val_loss=0.511, val_acc=0.731, val_auroc=0.777, val_F1=0.713]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99: 100%|██████████| 100/100 [00:00<00:00, 139.69it/s, v_num=41, loss=0.561, val_loss=0.511, val_acc=0.731, val_auroc=0.777, val_F1=0.713]\n"
     ]
    }
   ],
   "source": [
    "trainer.fit(model=MLP_model, train_dataloaders=train_dataloader, val_dataloaders=val_dataloader)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-07T16:42:26.804390Z",
     "start_time": "2023-10-07T16:41:14.130208Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/cgu3/opt/anaconda3/envs/Grape-Pi/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:438: PossibleUserWarning: The dataloader, test_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing: 0it [00:00, ?it/s]────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "         test_F1            0.6842639446258545\n",
      "        test_acc            0.7193140983581543\n",
      "       test_auroc           0.7619515061378479\n",
      "        test_loss           0.5236853361129761\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "text/plain": "[{'test_loss': 0.5236853361129761,\n  'test_acc': 0.7193140983581543,\n  'test_auroc': 0.7619515061378479,\n  'test_F1': 0.6842639446258545}]"
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.test(model=MLP_model, dataloaders=test_dataloader)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-07T16:42:26.871849Z",
     "start_time": "2023-10-07T16:42:26.739411Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/cgu3/opt/anaconda3/envs/Grape-Pi/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:438: PossibleUserWarning: The dataloader, predict_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting: 0it [00:00, ?it/s]"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 1 is out of bounds for dimension 1 with size 1",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mIndexError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[127], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m out \u001B[38;5;241m=\u001B[39m \u001B[43mtrainer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpredict\u001B[49m\u001B[43m(\u001B[49m\u001B[43mMLP_model\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdataloaders\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtest_dataloader\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m      2\u001B[0m out\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/Grape-Pi/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:852\u001B[0m, in \u001B[0;36mTrainer.predict\u001B[0;34m(self, model, dataloaders, datamodule, return_predictions, ckpt_path)\u001B[0m\n\u001B[1;32m    850\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstrategy\u001B[38;5;241m.\u001B[39m_lightning_module \u001B[38;5;241m=\u001B[39m model\n\u001B[1;32m    851\u001B[0m _verify_strategy_supports_compile(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlightning_module, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstrategy)\n\u001B[0;32m--> 852\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mcall\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_and_handle_interrupt\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    853\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_predict_impl\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdataloaders\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdatamodule\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mreturn_predictions\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mckpt_path\u001B[49m\n\u001B[1;32m    854\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/Grape-Pi/lib/python3.10/site-packages/pytorch_lightning/trainer/call.py:43\u001B[0m, in \u001B[0;36m_call_and_handle_interrupt\u001B[0;34m(trainer, trainer_fn, *args, **kwargs)\u001B[0m\n\u001B[1;32m     41\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m trainer\u001B[38;5;241m.\u001B[39mstrategy\u001B[38;5;241m.\u001B[39mlauncher \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m     42\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m trainer\u001B[38;5;241m.\u001B[39mstrategy\u001B[38;5;241m.\u001B[39mlauncher\u001B[38;5;241m.\u001B[39mlaunch(trainer_fn, \u001B[38;5;241m*\u001B[39margs, trainer\u001B[38;5;241m=\u001B[39mtrainer, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m---> 43\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mtrainer_fn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     45\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m _TunerExitException:\n\u001B[1;32m     46\u001B[0m     _call_teardown_hook(trainer)\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/Grape-Pi/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:894\u001B[0m, in \u001B[0;36mTrainer._predict_impl\u001B[0;34m(self, model, dataloaders, datamodule, return_predictions, ckpt_path)\u001B[0m\n\u001B[1;32m    889\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_data_connector\u001B[38;5;241m.\u001B[39mattach_data(model, predict_dataloaders\u001B[38;5;241m=\u001B[39mdataloaders, datamodule\u001B[38;5;241m=\u001B[39mdatamodule)\n\u001B[1;32m    891\u001B[0m ckpt_path \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_checkpoint_connector\u001B[38;5;241m.\u001B[39m_select_ckpt_path(\n\u001B[1;32m    892\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstate\u001B[38;5;241m.\u001B[39mfn, ckpt_path, model_provided\u001B[38;5;241m=\u001B[39mmodel_provided, model_connected\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlightning_module \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m    893\u001B[0m )\n\u001B[0;32m--> 894\u001B[0m results \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_run\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mckpt_path\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mckpt_path\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    896\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstate\u001B[38;5;241m.\u001B[39mstopped\n\u001B[1;32m    897\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpredicting \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/Grape-Pi/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:980\u001B[0m, in \u001B[0;36mTrainer._run\u001B[0;34m(self, model, ckpt_path)\u001B[0m\n\u001B[1;32m    975\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_signal_connector\u001B[38;5;241m.\u001B[39mregister_signal_handlers()\n\u001B[1;32m    977\u001B[0m \u001B[38;5;66;03m# ----------------------------\u001B[39;00m\n\u001B[1;32m    978\u001B[0m \u001B[38;5;66;03m# RUN THE TRAINER\u001B[39;00m\n\u001B[1;32m    979\u001B[0m \u001B[38;5;66;03m# ----------------------------\u001B[39;00m\n\u001B[0;32m--> 980\u001B[0m results \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_run_stage\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    982\u001B[0m \u001B[38;5;66;03m# ----------------------------\u001B[39;00m\n\u001B[1;32m    983\u001B[0m \u001B[38;5;66;03m# POST-Training CLEAN UP\u001B[39;00m\n\u001B[1;32m    984\u001B[0m \u001B[38;5;66;03m# ----------------------------\u001B[39;00m\n\u001B[1;32m    985\u001B[0m log\u001B[38;5;241m.\u001B[39mdebug(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__class__\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m: trainer tearing down\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/Grape-Pi/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:1018\u001B[0m, in \u001B[0;36mTrainer._run_stage\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m   1016\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_evaluation_loop\u001B[38;5;241m.\u001B[39mrun()\n\u001B[1;32m   1017\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpredicting:\n\u001B[0;32m-> 1018\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpredict_loop\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1019\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtraining:\n\u001B[1;32m   1020\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m isolate_rng():\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/Grape-Pi/lib/python3.10/site-packages/pytorch_lightning/loops/utilities.py:181\u001B[0m, in \u001B[0;36m_no_grad_context.<locals>._decorator\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m    179\u001B[0m     context_manager \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mno_grad\n\u001B[1;32m    180\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m context_manager():\n\u001B[0;32m--> 181\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mloop_run\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/Grape-Pi/lib/python3.10/site-packages/pytorch_lightning/loops/prediction_loop.py:112\u001B[0m, in \u001B[0;36m_PredictionLoop.run\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    110\u001B[0m     batch, batch_idx, dataloader_idx \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mnext\u001B[39m(data_fetcher)\n\u001B[1;32m    111\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbatch_progress\u001B[38;5;241m.\u001B[39mis_last_batch \u001B[38;5;241m=\u001B[39m data_fetcher\u001B[38;5;241m.\u001B[39mdone\n\u001B[0;32m--> 112\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_predict_step\u001B[49m\u001B[43m(\u001B[49m\u001B[43mbatch\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbatch_idx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdataloader_idx\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    113\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mStopIteration\u001B[39;00m:\n\u001B[1;32m    114\u001B[0m     \u001B[38;5;66;03m# this needs to wrap the `*_step` call too (not just `next`) for `dataloader_iter` support\u001B[39;00m\n\u001B[1;32m    115\u001B[0m     \u001B[38;5;28;01mbreak\u001B[39;00m\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/Grape-Pi/lib/python3.10/site-packages/pytorch_lightning/loops/prediction_loop.py:229\u001B[0m, in \u001B[0;36m_PredictionLoop._predict_step\u001B[0;34m(self, batch, batch_idx, dataloader_idx)\u001B[0m\n\u001B[1;32m    226\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbatch_progress\u001B[38;5;241m.\u001B[39mincrement_started()\n\u001B[1;32m    228\u001B[0m \u001B[38;5;66;03m# configure step_kwargs\u001B[39;00m\n\u001B[0;32m--> 229\u001B[0m predictions \u001B[38;5;241m=\u001B[39m \u001B[43mcall\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_strategy_hook\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrainer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mpredict_step\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mstep_kwargs\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mvalues\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    231\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbatch_progress\u001B[38;5;241m.\u001B[39mincrement_processed()\n\u001B[1;32m    233\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m predictions \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/Grape-Pi/lib/python3.10/site-packages/pytorch_lightning/trainer/call.py:293\u001B[0m, in \u001B[0;36m_call_strategy_hook\u001B[0;34m(trainer, hook_name, *args, **kwargs)\u001B[0m\n\u001B[1;32m    290\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m    292\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m trainer\u001B[38;5;241m.\u001B[39mprofiler\u001B[38;5;241m.\u001B[39mprofile(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m[Strategy]\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mtrainer\u001B[38;5;241m.\u001B[39mstrategy\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__class__\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m.\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mhook_name\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m):\n\u001B[0;32m--> 293\u001B[0m     output \u001B[38;5;241m=\u001B[39m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    295\u001B[0m \u001B[38;5;66;03m# restore current_fx when nested context\u001B[39;00m\n\u001B[1;32m    296\u001B[0m pl_module\u001B[38;5;241m.\u001B[39m_current_fx_name \u001B[38;5;241m=\u001B[39m prev_fx_name\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/Grape-Pi/lib/python3.10/site-packages/pytorch_lightning/strategies/strategy.py:413\u001B[0m, in \u001B[0;36mStrategy.predict_step\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m    411\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mprecision_plugin\u001B[38;5;241m.\u001B[39mpredict_step_context():\n\u001B[1;32m    412\u001B[0m     \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodel, PredictStep)\n\u001B[0;32m--> 413\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpredict_step\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[0;32mIn[118], line 72\u001B[0m, in \u001B[0;36mMLP.predict_step\u001B[0;34m(self, batch, batch_idx)\u001B[0m\n\u001B[1;32m     70\u001B[0m logits \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m(x)\u001B[38;5;241m.\u001B[39msqueeze(\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m)\n\u001B[1;32m     71\u001B[0m pred_prob \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mnn\u001B[38;5;241m.\u001B[39mfunctional\u001B[38;5;241m.\u001B[39msigmoid(logits)\n\u001B[0;32m---> 72\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m (ids, x[:, \u001B[38;5;241m0\u001B[39m], \u001B[43mx\u001B[49m\u001B[43m[\u001B[49m\u001B[43m:\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m]\u001B[49m, pred_prob, y)\n",
      "\u001B[0;31mIndexError\u001B[0m: index 1 is out of bounds for dimension 1 with size 1"
     ]
    }
   ],
   "source": [
    "out = trainer.predict(MLP_model, dataloaders=test_dataloader)\n",
    "out"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-06T15:54:43.852553Z",
     "start_time": "2023-10-06T15:54:41.014327Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "accession, raw_prob, mRNA, pred_prob, soft_label = zip(*out)\n",
    "accession = [item for sublist in accession for item in sublist]\n",
    "raw_prob = [item.item() for sublist in raw_prob for item in sublist]\n",
    "mRNA = [item.item() for sublist in mRNA for item in sublist]\n",
    "pred_prob = [item.item() for sublist in pred_prob for item in sublist]\n",
    "soft_label = [item.item() for sublist in soft_label for item in sublist]\n",
    "pd.DataFrame({'accession': accession, 'raw_prob': raw_prob, 'mRNA': mRNA, 'pred_prob': pred_prob, 'soft_label': soft_label})"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-10-05T05:56:26.462766Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "outputs": [
    {
     "data": {
      "text/plain": "<torch.utils.data.dataloader.DataLoader at 0x156841660>"
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataloader"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-04T19:24:41.068889Z",
     "start_time": "2023-10-04T19:24:40.966076Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "outputs": [
    {
     "data": {
      "text/plain": "Launching TensorBoard..."
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%reload_ext tensorboard\n",
    "%tensorboard --logdir=lightning_logs/"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-22T21:19:13.658811Z",
     "start_time": "2023-09-22T21:19:09.970212Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
