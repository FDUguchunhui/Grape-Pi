{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "# %connect_info\n",
    "%qtconsole"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "end_time": "2023-10-17T15:28:29.741876Z",
     "start_time": "2023-10-17T15:28:29.726483Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from graphgym.custom_graphgym.loader.protein import ProteinDataset\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-17T15:28:32.192051Z",
     "start_time": "2023-10-17T15:28:29.732852Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "os.chdir('/Users/cgu3/Documents/Grape-Pi')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-17T15:28:32.197741Z",
     "start_time": "2023-10-17T15:28:32.192708Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Import data from csv fies"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    },
    "ExecuteTime": {
     "end_time": "2023-10-12T03:03:24.211502Z",
     "start_time": "2023-10-12T03:03:23.909922Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "\n",
    "# dataset = ProteinDataset(\"data/yeast-ORBI\", numeric_columns=['protein probability'], label_column=None)\n",
    "# dataset = ProteinBatchDataset(\"data/yeast-LCQ\", numeric_params=['protein probability'])\n",
    "# dataset = ProteinBatchDataset(\"data/yeast-ORBI-mRNA\", numeric_params=['protein probability', 'mRNA(M)'])\n",
    "# dataset = ProteinBatchDataset(\"data/yeast-LCQ-mRNA\", numeric_params=['protein probability', 'mRNA(M)'])\n",
    "# dataset = ProteinDataset(\"data/single-soft-label\", numeric_columns=['protein_probability', 'mRNA_TPM'], label_column=None)\n",
    "protein_dataset = ProteinDataset(\"data/single\", numeric_columns=['protein_probability', 'mRNA_TPM'], label_column=None)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-17T15:28:32.207263Z",
     "start_time": "2023-10-17T15:28:32.195115Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "      protein.Accession  protein_probability  protein_probability_soft_label  \\\n0            A0A075B6H7             0.700122                        0.267383   \n1            A0A075B6H8             0.286947                        0.056265   \n2            A0A075B6L6             0.943529                        0.140940   \n3            A0A075B6N1             0.289680                        0.153119   \n4            A0A075B6N2             0.259341                        0.128836   \n...                 ...                  ...                             ...   \n12532            Q9UI54             0.000000                        0.000000   \n12533            Q9Y3F1             0.000000                        0.197423   \n12534            Q9Y6C7             0.000000                        0.093179   \n12535            Q9Y6Z2             0.000000                        0.000000   \n12536            X6R8R1             0.000000                        0.283767   \n\n       hard_label gene_symbol  mRNA_TPM  \n0               0     IGKV3-7  0.000000  \n1               0   IGKV1D-42  0.000000  \n2               0     TRBV7-3  0.000000  \n3               0      TRBV19  0.000000  \n4               0    TRBV20-1  0.370502  \n...           ...         ...       ...  \n12532           0           0  0.000000  \n12533           0           0  0.000000  \n12534           0   LINC00312  0.000000  \n12535           0   LINC01558  0.053100  \n12536           0      SYT15B  0.000000  \n\n[12537 rows x 6 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>protein.Accession</th>\n      <th>protein_probability</th>\n      <th>protein_probability_soft_label</th>\n      <th>hard_label</th>\n      <th>gene_symbol</th>\n      <th>mRNA_TPM</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>A0A075B6H7</td>\n      <td>0.700122</td>\n      <td>0.267383</td>\n      <td>0</td>\n      <td>IGKV3-7</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>A0A075B6H8</td>\n      <td>0.286947</td>\n      <td>0.056265</td>\n      <td>0</td>\n      <td>IGKV1D-42</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>A0A075B6L6</td>\n      <td>0.943529</td>\n      <td>0.140940</td>\n      <td>0</td>\n      <td>TRBV7-3</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>A0A075B6N1</td>\n      <td>0.289680</td>\n      <td>0.153119</td>\n      <td>0</td>\n      <td>TRBV19</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>A0A075B6N2</td>\n      <td>0.259341</td>\n      <td>0.128836</td>\n      <td>0</td>\n      <td>TRBV20-1</td>\n      <td>0.370502</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>12532</th>\n      <td>Q9UI54</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>12533</th>\n      <td>Q9Y3F1</td>\n      <td>0.000000</td>\n      <td>0.197423</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>12534</th>\n      <td>Q9Y6C7</td>\n      <td>0.000000</td>\n      <td>0.093179</td>\n      <td>0</td>\n      <td>LINC00312</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>12535</th>\n      <td>Q9Y6Z2</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0</td>\n      <td>LINC01558</td>\n      <td>0.053100</td>\n    </tr>\n    <tr>\n      <th>12536</th>\n      <td>X6R8R1</td>\n      <td>0.000000</td>\n      <td>0.283767</td>\n      <td>0</td>\n      <td>SYT15B</td>\n      <td>0.000000</td>\n    </tr>\n  </tbody>\n</table>\n<p>12537 rows × 6 columns</p>\n</div>"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "protein_file = [f for f in os.listdir('data/single/raw/protein') if f.endswith('.csv')][0]\n",
    "df = pd.read_csv(os.path.join('data/single/raw/protein', protein_file))\n",
    "ids = df['protein.Accession'].values\n",
    "# df = pd.read_csv('/Users/cgu3/Documents/data/SG_combined_protein_0982_with_protein_probability.csv')\n",
    "df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-17T15:28:32.224040Z",
     "start_time": "2023-10-17T15:28:32.209Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, data, labels, ids, train_mask=None, val_mask=None, test_mask=None):\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "        self.ids = ids\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        sample_data = self.data[index]\n",
    "        sample_label = self.labels[index]\n",
    "        sample_id = self.ids[index]\n",
    "        return sample_data, sample_label, sample_id\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-17T15:28:32.228352Z",
     "start_time": "2023-10-17T15:28:32.224797Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, Subset\n",
    "dataset = CustomDataset(protein_dataset.x, protein_dataset.y, ids)\n",
    "\n",
    "train_indices = torch.nonzero(protein_dataset.train_mask).squeeze().tolist()\n",
    "train_dataset = Subset(dataset, train_indices)\n",
    "\n",
    "val_indices = torch.nonzero(protein_dataset.val_mask).squeeze().tolist()\n",
    "val_dataset = Subset(dataset, val_indices)\n",
    "\n",
    "test_indices = torch.nonzero(protein_dataset.test_mask).squeeze().tolist()\n",
    "test_dataset = Subset(dataset, test_indices)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-17T15:28:32.229753Z",
     "start_time": "2023-10-17T15:28:32.227564Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "<torch._C.Generator at 0x126ed6c30>"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "torch.manual_seed(12345)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=64, shuffle=False)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=64, shuffle=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-17T15:28:32.233786Z",
     "start_time": "2023-10-17T15:28:32.230417Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "import os\n",
    "from torch import optim, nn, utils, Tensor\n",
    "import pytorch_lightning as pl\n",
    "from torchmetrics.classification import BinaryAUROC, BinaryAccuracy, BinaryF1Score\n",
    "import torch\n",
    "\n",
    "\n",
    "# define the LightningModule\n",
    "class MLP(pl.LightningModule):\n",
    "    def __init__(self, num_features, hidden_channels, num_classes, criterion):\n",
    "        super().__init__()\n",
    "        torch.manual_seed(12345)\n",
    "        self.lin1 = nn.Linear(num_features, hidden_channels)\n",
    "        self.lin2 = nn.Linear(hidden_channels, num_classes)\n",
    "        # self.lin3 = nn.Linear(hidden_channels, num_classes)\n",
    "        self.criterion = criterion\n",
    "        self.val_auroc = BinaryAUROC()\n",
    "        self.test_auroc = BinaryAUROC()\n",
    "        self.val_accuracy = BinaryAccuracy()\n",
    "        self.test_accuracy = BinaryAccuracy()\n",
    "        self.val_F1 = BinaryF1Score()\n",
    "        self.test_F1 = BinaryF1Score()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.lin1(x)\n",
    "        x = x.relu()\n",
    "        x = self.lin2(x)\n",
    "        return x\n",
    "\n",
    "    def get_auc(self, out, target):\n",
    "        return self.auroc(out, target)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y, id = batch\n",
    "        logits = self(x).squeeze(-1)  # Perform a single forward pass.\n",
    "\n",
    "        loss = self.criterion(logits, y)  # Compute the loss solely based on the training nodes.\n",
    "        values = {\"loss\": loss}\n",
    "        self.log_dict(values, prog_bar=True)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y, ids = batch\n",
    "        logits = self(x).squeeze(-1)  # Perform a single forward pass.\n",
    "        self.val_accuracy.update(logits, y)\n",
    "        loss = self.criterion(logits, y)  # Compute the loss solely based on the training nodes.\n",
    "        self.val_auroc.update(logits, y)\n",
    "        self.val_F1.update(logits, y)\n",
    "        values = {\"val_loss\": loss, \"val_acc\": self.val_accuracy, \"val_auroc\": self.val_auroc, \"val_F1\": self.val_F1}\n",
    "        self.log_dict(values, prog_bar=True, on_step=False, on_epoch=True)\n",
    "        return loss\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        x, y, ids = batch\n",
    "        logits = self(x).squeeze(-1)\n",
    "        self.test_accuracy.update(logits, y)\n",
    "        loss = self.criterion(logits, y)\n",
    "        self.test_auroc.update(logits, y)\n",
    "        self.test_F1.update(logits, y)\n",
    "        values = {\"test_loss\": loss, \"test_acc\": self.test_accuracy, \"test_auroc\": self.test_auroc, \"test_F1\": self.test_F1}\n",
    "        self.log_dict(values, prog_bar=True, on_step=False, on_epoch=True)\n",
    "        return loss\n",
    "    \n",
    "    def predict_step(self, batch, batch_idx):\n",
    "        x, y, ids = batch\n",
    "        ids = [item for sublist in ids for item in sublist]\n",
    "        logits = self(x).squeeze(-1)\n",
    "        pred_prob = torch.nn.functional.sigmoid(logits)\n",
    "        return (ids, x[:, 0], x[:, 1], pred_prob, y)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = optim.Adam(self.parameters(), lr=1e-3)\n",
    "        return optimizer\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-17T15:28:32.239193Z",
     "start_time": "2023-10-17T15:28:32.238063Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "# init the autoencoder\n",
    "MLP_model = MLP(1, 1, 1, criterion = torch.nn.BCEWithLogitsLoss())\n",
    "# MLP_model = MLP(dataset.num_node_features, 10, 2, criterion = torch.nn.CrossEntropyLoss())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-17T15:28:32.281482Z",
     "start_time": "2023-10-17T15:28:32.240197Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "import sys\n",
    "from pytorch_lightning.callbacks import TQDMProgressBar\n",
    "\n",
    "\n",
    "class MyProgressBar(TQDMProgressBar):\n",
    "    def init_validation_tqdm(self):\n",
    "        bar = super().init_validation_tqdm()\n",
    "        if not sys.stdout.isatty():\n",
    "            bar.disable = True\n",
    "        return bar\n",
    "\n",
    "    def init_predict_tqdm(self):\n",
    "        bar = super().init_predict_tqdm()\n",
    "        if not sys.stdout.isatty():\n",
    "            bar.disable = True\n",
    "        return bar\n",
    "\n",
    "    def init_test_tqdm(self):\n",
    "        bar = super().init_test_tqdm()\n",
    "        if not sys.stdout.isatty():\n",
    "            bar.disable = True\n",
    "        return bar\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-17T15:28:32.281556Z",
     "start_time": "2023-10-17T15:28:32.263611Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "import pytorch_lightning as pl\n",
    "trainer = pl.Trainer(limit_train_batches=100, max_epochs=100, enable_progress_bar=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-17T15:28:32.397846Z",
     "start_time": "2023-10-17T15:28:32.266105Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name          | Type              | Params\n",
      "----------------------------------------------------\n",
      "0 | lin1          | Linear            | 2     \n",
      "1 | lin2          | Linear            | 2     \n",
      "2 | criterion     | BCEWithLogitsLoss | 0     \n",
      "3 | val_auroc     | BinaryAUROC       | 0     \n",
      "4 | test_auroc    | BinaryAUROC       | 0     \n",
      "5 | val_accuracy  | BinaryAccuracy    | 0     \n",
      "6 | test_accuracy | BinaryAccuracy    | 0     \n",
      "7 | val_F1        | BinaryF1Score     | 0     \n",
      "8 | test_F1       | BinaryF1Score     | 0     \n",
      "----------------------------------------------------\n",
      "4         Trainable params\n",
      "0         Non-trainable params\n",
      "4         Total params\n",
      "0.000     Total estimated model params size (MB)\n"
     ]
    }
   ],
   "source": [
    "trainer.fit(model=MLP_model, train_dataloaders=train_dataloader, val_dataloaders=val_dataloader)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "ExecuteTime": {
     "start_time": "2023-10-17T15:28:32.398796Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "trainer.test(model=MLP_model, dataloaders=test_dataloader)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/cgu3/anaconda3/envs/grape-pi/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 1 is out of bounds for dimension 1 with size 1",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mIndexError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[200], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m out \u001B[38;5;241m=\u001B[39m \u001B[43mtrainer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpredict\u001B[49m\u001B[43m(\u001B[49m\u001B[43mMLP_model\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdataloaders\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtest_dataloader\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m      2\u001B[0m out\n",
      "File \u001B[0;32m~/anaconda3/envs/grape-pi/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:865\u001B[0m, in \u001B[0;36mTrainer.predict\u001B[0;34m(self, model, dataloaders, datamodule, return_predictions, ckpt_path)\u001B[0m\n\u001B[1;32m    863\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstate\u001B[38;5;241m.\u001B[39mstatus \u001B[38;5;241m=\u001B[39m TrainerStatus\u001B[38;5;241m.\u001B[39mRUNNING\n\u001B[1;32m    864\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpredicting \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[0;32m--> 865\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mcall\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_and_handle_interrupt\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    866\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_predict_impl\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdataloaders\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdatamodule\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mreturn_predictions\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mckpt_path\u001B[49m\n\u001B[1;32m    867\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/anaconda3/envs/grape-pi/lib/python3.10/site-packages/pytorch_lightning/trainer/call.py:44\u001B[0m, in \u001B[0;36m_call_and_handle_interrupt\u001B[0;34m(trainer, trainer_fn, *args, **kwargs)\u001B[0m\n\u001B[1;32m     42\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m trainer\u001B[38;5;241m.\u001B[39mstrategy\u001B[38;5;241m.\u001B[39mlauncher \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m     43\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m trainer\u001B[38;5;241m.\u001B[39mstrategy\u001B[38;5;241m.\u001B[39mlauncher\u001B[38;5;241m.\u001B[39mlaunch(trainer_fn, \u001B[38;5;241m*\u001B[39margs, trainer\u001B[38;5;241m=\u001B[39mtrainer, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m---> 44\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mtrainer_fn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     46\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m _TunerExitException:\n\u001B[1;32m     47\u001B[0m     _call_teardown_hook(trainer)\n",
      "File \u001B[0;32m~/anaconda3/envs/grape-pi/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:904\u001B[0m, in \u001B[0;36mTrainer._predict_impl\u001B[0;34m(self, model, dataloaders, datamodule, return_predictions, ckpt_path)\u001B[0m\n\u001B[1;32m    900\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstate\u001B[38;5;241m.\u001B[39mfn \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m    901\u001B[0m ckpt_path \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_checkpoint_connector\u001B[38;5;241m.\u001B[39m_select_ckpt_path(\n\u001B[1;32m    902\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstate\u001B[38;5;241m.\u001B[39mfn, ckpt_path, model_provided\u001B[38;5;241m=\u001B[39mmodel_provided, model_connected\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlightning_module \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m    903\u001B[0m )\n\u001B[0;32m--> 904\u001B[0m results \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_run\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mckpt_path\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mckpt_path\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    906\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstate\u001B[38;5;241m.\u001B[39mstopped\n\u001B[1;32m    907\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpredicting \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m\n",
      "File \u001B[0;32m~/anaconda3/envs/grape-pi/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:990\u001B[0m, in \u001B[0;36mTrainer._run\u001B[0;34m(self, model, ckpt_path)\u001B[0m\n\u001B[1;32m    985\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_signal_connector\u001B[38;5;241m.\u001B[39mregister_signal_handlers()\n\u001B[1;32m    987\u001B[0m \u001B[38;5;66;03m# ----------------------------\u001B[39;00m\n\u001B[1;32m    988\u001B[0m \u001B[38;5;66;03m# RUN THE TRAINER\u001B[39;00m\n\u001B[1;32m    989\u001B[0m \u001B[38;5;66;03m# ----------------------------\u001B[39;00m\n\u001B[0;32m--> 990\u001B[0m results \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_run_stage\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    992\u001B[0m \u001B[38;5;66;03m# ----------------------------\u001B[39;00m\n\u001B[1;32m    993\u001B[0m \u001B[38;5;66;03m# POST-Training CLEAN UP\u001B[39;00m\n\u001B[1;32m    994\u001B[0m \u001B[38;5;66;03m# ----------------------------\u001B[39;00m\n\u001B[1;32m    995\u001B[0m log\u001B[38;5;241m.\u001B[39mdebug(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__class__\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m: trainer tearing down\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[0;32m~/anaconda3/envs/grape-pi/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:1031\u001B[0m, in \u001B[0;36mTrainer._run_stage\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m   1029\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_evaluation_loop\u001B[38;5;241m.\u001B[39mrun()\n\u001B[1;32m   1030\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpredicting:\n\u001B[0;32m-> 1031\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpredict_loop\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1032\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtraining:\n\u001B[1;32m   1033\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m isolate_rng():\n",
      "File \u001B[0;32m~/anaconda3/envs/grape-pi/lib/python3.10/site-packages/pytorch_lightning/loops/utilities.py:181\u001B[0m, in \u001B[0;36m_no_grad_context.<locals>._decorator\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m    179\u001B[0m     context_manager \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mno_grad\n\u001B[1;32m    180\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m context_manager():\n\u001B[0;32m--> 181\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mloop_run\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/anaconda3/envs/grape-pi/lib/python3.10/site-packages/pytorch_lightning/loops/prediction_loop.py:122\u001B[0m, in \u001B[0;36m_PredictionLoop.run\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    120\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbatch_progress\u001B[38;5;241m.\u001B[39mis_last_batch \u001B[38;5;241m=\u001B[39m data_fetcher\u001B[38;5;241m.\u001B[39mdone\n\u001B[1;32m    121\u001B[0m     \u001B[38;5;66;03m# run step hooks\u001B[39;00m\n\u001B[0;32m--> 122\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_predict_step\u001B[49m\u001B[43m(\u001B[49m\u001B[43mbatch\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbatch_idx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdataloader_idx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdataloader_iter\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    123\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mStopIteration\u001B[39;00m:\n\u001B[1;32m    124\u001B[0m     \u001B[38;5;66;03m# this needs to wrap the `*_step` call too (not just `next`) for `dataloader_iter` support\u001B[39;00m\n\u001B[1;32m    125\u001B[0m     \u001B[38;5;28;01mbreak\u001B[39;00m\n",
      "File \u001B[0;32m~/anaconda3/envs/grape-pi/lib/python3.10/site-packages/pytorch_lightning/loops/prediction_loop.py:250\u001B[0m, in \u001B[0;36m_PredictionLoop._predict_step\u001B[0;34m(self, batch, batch_idx, dataloader_idx, dataloader_iter)\u001B[0m\n\u001B[1;32m    244\u001B[0m \u001B[38;5;66;03m# configure step_kwargs\u001B[39;00m\n\u001B[1;32m    245\u001B[0m step_args \u001B[38;5;241m=\u001B[39m (\n\u001B[1;32m    246\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_build_step_args_from_hook_kwargs(hook_kwargs, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpredict_step\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m    247\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m using_dataloader_iter\n\u001B[1;32m    248\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m (dataloader_iter,)\n\u001B[1;32m    249\u001B[0m )\n\u001B[0;32m--> 250\u001B[0m predictions \u001B[38;5;241m=\u001B[39m \u001B[43mcall\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_strategy_hook\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrainer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mpredict_step\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mstep_args\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    251\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m predictions \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    252\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_warning_cache\u001B[38;5;241m.\u001B[39mwarn(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpredict returned None if it was on purpose, ignore this warning...\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[0;32m~/anaconda3/envs/grape-pi/lib/python3.10/site-packages/pytorch_lightning/trainer/call.py:309\u001B[0m, in \u001B[0;36m_call_strategy_hook\u001B[0;34m(trainer, hook_name, *args, **kwargs)\u001B[0m\n\u001B[1;32m    306\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m    308\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m trainer\u001B[38;5;241m.\u001B[39mprofiler\u001B[38;5;241m.\u001B[39mprofile(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m[Strategy]\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mtrainer\u001B[38;5;241m.\u001B[39mstrategy\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__class__\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m.\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mhook_name\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m):\n\u001B[0;32m--> 309\u001B[0m     output \u001B[38;5;241m=\u001B[39m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    311\u001B[0m \u001B[38;5;66;03m# restore current_fx when nested context\u001B[39;00m\n\u001B[1;32m    312\u001B[0m pl_module\u001B[38;5;241m.\u001B[39m_current_fx_name \u001B[38;5;241m=\u001B[39m prev_fx_name\n",
      "File \u001B[0;32m~/anaconda3/envs/grape-pi/lib/python3.10/site-packages/pytorch_lightning/strategies/strategy.py:429\u001B[0m, in \u001B[0;36mStrategy.predict_step\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m    427\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodel \u001B[38;5;241m!=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlightning_module:\n\u001B[1;32m    428\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_redirection(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodel, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlightning_module, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpredict_step\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m--> 429\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlightning_module\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpredict_step\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[0;32mIn[194], line 68\u001B[0m, in \u001B[0;36mMLP.predict_step\u001B[0;34m(self, batch, batch_idx)\u001B[0m\n\u001B[1;32m     66\u001B[0m logits \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m(x)\u001B[38;5;241m.\u001B[39msqueeze(\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m)\n\u001B[1;32m     67\u001B[0m pred_prob \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mnn\u001B[38;5;241m.\u001B[39mfunctional\u001B[38;5;241m.\u001B[39msigmoid(logits)\n\u001B[0;32m---> 68\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m (ids, x[:, \u001B[38;5;241m0\u001B[39m], \u001B[43mx\u001B[49m\u001B[43m[\u001B[49m\u001B[43m:\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m]\u001B[49m, pred_prob, y)\n",
      "\u001B[0;31mIndexError\u001B[0m: index 1 is out of bounds for dimension 1 with size 1"
     ]
    }
   ],
   "source": [
    "out = trainer.predict(MLP_model, dataloaders=test_dataloader)\n",
    "out"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-16T21:46:36.022187Z",
     "start_time": "2023-10-16T21:46:35.936187Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/cgu3/opt/anaconda3/envs/Grape-Pi/lib/python3.10/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:617: UserWarning: Checkpoint directory /Users/cgu3/Documents/Grape-Pi/lightning_logs/version_97/checkpoints exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "\n",
      "  | Name             | Type              | Params\n",
      "-------------------------------------------------------\n",
      "0 | lin1             | Linear            | 20    \n",
      "1 | lin2             | Linear            | 11    \n",
      "2 | criterion        | BCEWithLogitsLoss | 0     \n",
      "3 | train_collection | MetricCollection  | 0     \n",
      "4 | val_collection   | MetricCollection  | 0     \n",
      "5 | test_collection  | MetricCollection  | 0     \n",
      "-------------------------------------------------------\n",
      "31        Trainable params\n",
      "0         Non-trainable params\n",
      "31        Total params\n",
      "0.000     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10:  45%|████▍     | 47/105 [01:47<02:13,  2.29s/it, v_num=97, loss=-.203, val_loss=-.0114, val_acc=0.760, val_auc=0.830, val_f1=0.711] \n",
      "                                                                            "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/cgu3/opt/anaconda3/envs/Grape-Pi/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:438: PossibleUserWarning: The dataloader, val_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "/Users/cgu3/opt/anaconda3/envs/Grape-Pi/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:438: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: 100%|██████████| 105/105 [00:00<00:00, 143.22it/s, v_num=97, loss=-.314] \n",
      "Epoch 11: 100%|██████████| 105/105 [00:00<00:00, 146.27it/s, v_num=97, loss=0.736, val_loss=-.0882, val_acc=0.764, val_auc=0.830, val_f1=0.721]  \n",
      "Epoch 12: 100%|██████████| 105/105 [00:00<00:00, 152.38it/s, v_num=97, loss=-.784, val_loss=-.141, val_acc=0.766, val_auc=0.830, val_f1=0.724] \n",
      "Epoch 13: 100%|██████████| 105/105 [00:00<00:00, 153.06it/s, v_num=97, loss=0.166, val_loss=-.192, val_acc=0.765, val_auc=0.830, val_f1=0.723]\n",
      "Epoch 14: 100%|██████████| 105/105 [00:00<00:00, 151.92it/s, v_num=97, loss=-.323, val_loss=-.241, val_acc=0.765, val_auc=0.830, val_f1=0.718] \n",
      "Epoch 15: 100%|██████████| 105/105 [00:00<00:00, 154.61it/s, v_num=97, loss=-.104, val_loss=-.298, val_acc=0.765, val_auc=0.830, val_f1=0.723]  \n",
      "Epoch 16: 100%|██████████| 105/105 [00:00<00:00, 156.63it/s, v_num=97, loss=-.197, val_loss=-.352, val_acc=0.772, val_auc=0.830, val_f1=0.735]  \n",
      "Epoch 17: 100%|██████████| 105/105 [00:00<00:00, 146.07it/s, v_num=97, loss=-1.27, val_loss=-.408, val_acc=0.766, val_auc=0.830, val_f1=0.724]\n",
      "Epoch 18: 100%|██████████| 105/105 [00:00<00:00, 147.83it/s, v_num=97, loss=-2.42, val_loss=-.467, val_acc=0.765, val_auc=0.830, val_f1=0.723] \n",
      "Epoch 19: 100%|██████████| 105/105 [00:00<00:00, 145.77it/s, v_num=97, loss=-.0566, val_loss=-.528, val_acc=0.766, val_auc=0.830, val_f1=0.724]\n",
      "Epoch 20: 100%|██████████| 105/105 [00:00<00:00, 150.87it/s, v_num=97, loss=-1.16, val_loss=-.591, val_acc=0.764, val_auc=0.830, val_f1=0.721] \n",
      "Epoch 21: 100%|██████████| 105/105 [00:00<00:00, 148.15it/s, v_num=97, loss=0.0126, val_loss=-.656, val_acc=0.764, val_auc=0.830, val_f1=0.721]\n",
      "Epoch 22: 100%|██████████| 105/105 [00:00<00:00, 143.99it/s, v_num=97, loss=-.245, val_loss=-.724, val_acc=0.764, val_auc=0.830, val_f1=0.720] \n",
      "Epoch 23: 100%|██████████| 105/105 [00:00<00:00, 163.27it/s, v_num=97, loss=-1.71, val_loss=-.789, val_acc=0.764, val_auc=0.830, val_f1=0.720]\n",
      "Epoch 24: 100%|██████████| 105/105 [00:00<00:00, 155.39it/s, v_num=97, loss=1.460, val_loss=-.860, val_acc=0.765, val_auc=0.830, val_f1=0.722]\n",
      "Epoch 25: 100%|██████████| 105/105 [00:00<00:00, 151.49it/s, v_num=97, loss=-3.33, val_loss=-.932, val_acc=0.764, val_auc=0.830, val_f1=0.720]\n",
      "Epoch 26: 100%|██████████| 105/105 [00:00<00:00, 157.02it/s, v_num=97, loss=-1.60, val_loss=-1.01, val_acc=0.764, val_auc=0.830, val_f1=0.720]\n",
      "Epoch 27: 100%|██████████| 105/105 [00:00<00:00, 149.74it/s, v_num=97, loss=-.413, val_loss=-1.08, val_acc=0.765, val_auc=0.830, val_f1=0.718] \n",
      "Epoch 28: 100%|██████████| 105/105 [00:00<00:00, 154.82it/s, v_num=97, loss=-1.27, val_loss=-1.16, val_acc=0.764, val_auc=0.830, val_f1=0.717] \n",
      "Epoch 29: 100%|██████████| 105/105 [00:00<00:00, 152.59it/s, v_num=97, loss=-.292, val_loss=-1.24, val_acc=0.763, val_auc=0.830, val_f1=0.716]\n",
      "Epoch 30: 100%|██████████| 105/105 [00:00<00:00, 128.96it/s, v_num=97, loss=-1.61, val_loss=-1.33, val_acc=0.763, val_auc=0.830, val_f1=0.716]  \n",
      "Epoch 31:  13%|█▎        | 14/105 [00:00<00:00, 148.83it/s, v_num=97, loss=-1.21, val_loss=-1.41, val_acc=0.759, val_auc=0.830, val_f1=0.708] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/cgu3/opt/anaconda3/envs/Grape-Pi/lib/python3.10/site-packages/pytorch_lightning/trainer/call.py:53: UserWarning: Detected KeyboardInterrupt, attempting graceful shutdown...\n",
      "  rank_zero_warn(\"Detected KeyboardInterrupt, attempting graceful shutdown...\")\n"
     ]
    }
   ],
   "source": [
    "accession, raw_prob, mRNA, pred_prob, soft_label = zip(*out)\n",
    "accession = [item for sublist in accession for item in sublist]\n",
    "raw_prob = [item.item() for sublist in raw_prob for item in sublist]\n",
    "mRNA = [item.item() for sublist in mRNA for item in sublist]\n",
    "pred_prob = [item.item() for sublist in pred_prob for item in sublist]\n",
    "soft_label = [item.item() for sublist in soft_label for item in sublist]\n",
    "pd.DataFrame({'accession': accession, 'raw_prob': raw_prob, 'mRNA': mRNA, 'pred_prob': pred_prob, 'soft_label': soft_label})"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-12T02:34:30.613594Z",
     "start_time": "2023-10-12T02:34:14.340022Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "outputs": [
    {
     "data": {
      "text/plain": "<torch.utils.data.dataloader.DataLoader at 0x156841660>"
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataloader"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-04T19:24:41.068889Z",
     "start_time": "2023-10-04T19:24:40.966076Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "outputs": [
    {
     "data": {
      "text/plain": "Launching TensorBoard..."
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%reload_ext tensorboard\n",
    "%tensorboard --logdir=lightning_logs/"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-22T21:19:13.658811Z",
     "start_time": "2023-09-22T21:19:09.970212Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
