{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "# this notebook is used for evaluation performance of logistic-calibrated raw protein probability and MLP with raw protein probability and mRNA as input "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-15T23:19:23.152071Z",
     "start_time": "2023-10-15T23:19:23.118024Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "end_time": "2023-10-15T23:19:25.879888Z",
     "start_time": "2023-10-15T23:19:23.123768Z"
    }
   },
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from graphgym.custom_graphgym.loader.protein import ProteinDataset\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# %connect_info\n",
    "# %qtconsole"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "end_time": "2023-10-15T23:19:25.882041Z",
     "start_time": "2023-10-15T23:19:25.880060Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Import data from csv fies"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rebuilding...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "os.chdir('/Users/cgu3/Documents/Grape-Pi')\n",
    "dataset = ProteinDataset(\"data/yeast-ORBI\", numeric_columns=['protein_probability'], label_column=None, rebuild=True)\n",
    "# dataset = ProteinDataset(\"data/yeast-ORBI\", numeric_columns=['protein_probability', 'mRNA(M)'], label_column=None, rebuild=True)\n",
    "# dataset = ProteinDataset(\"data/yeast-LCQ\", numeric_columns=['protein_probability'], label_column=None, rebuild=True)\n",
    "# dataset = ProteinDataset(\"data/yeast-LCQ\", numeric_columns=['protein_probability', 'mRNA(M)'], label_column=None, rebuild=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-15T23:19:53.283490Z",
     "start_time": "2023-10-15T23:19:51.846951Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[0.9600],\n        [0.0000],\n        [0.0000],\n        ...,\n        [1.0000],\n        [1.0000],\n        [1.0000]])"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.x"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-15T23:19:53.286803Z",
     "start_time": "2023-10-15T23:19:53.283352Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([2822, 2311])"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "tensor([366, 276])"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "tensor([363, 279])"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.y[dataset.train_mask].long().bincount()\n",
    "dataset.y[dataset.val_mask].long().bincount()\n",
    "dataset.y[dataset.test_mask].long().bincount()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-15T23:19:53.291164Z",
     "start_time": "2023-10-15T23:19:53.286184Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of node features: 1\n",
      "Number of edge features: 0\n",
      "Number of training nodes: 5133\n"
     ]
    }
   ],
   "source": [
    "# print(f'Number of nodes: {dataset.num_nodes}')\n",
    "print(f'Number of node features: {dataset.num_node_features}')\n",
    "# print(f'Number of edges: {dataset.num_edges}')\n",
    "print(f'Number of edge features: {dataset.num_edge_features}')\n",
    "# print(f'Average node degree: {dataset.num_edges / dataset.num_nodes:.2f}')\n",
    "print(f'Number of training nodes: {dataset.train_mask.sum()}')\n",
    "# print(f'Training node label rate: {int(dataset.train_mask.sum()) / dataset.num_nodes:.2f}')\n",
    "# print(f'Validation node label rate: {int(dataset.val_mask.sum()) / dataset.num_nodes:.2f}')\n",
    "# print(f'Test node label rate: {int(dataset.test_mask.sum()) / dataset.num_nodes:.2f}')\n",
    "# print(f'Has isolated nodes: {dataset.has_isolated_nodes()}')\n",
    "# print(f'Has self-loops: {dataset.has_self_loops()}')\n",
    "# print(f'Is undirected: {dataset.is_undirected()}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-15T23:19:53.297970Z",
     "start_time": "2023-10-15T23:19:53.291771Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "train_dataset = torch.utils.data.TensorDataset(dataset.x[dataset.train_mask], dataset.y[dataset.train_mask])\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=64, shuffle=True, num_workers=4)\n",
    "val_dataset = torch.utils.data.TensorDataset(dataset.x[dataset.val_mask], dataset.y[dataset.val_mask])\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=64, shuffle=False, num_workers=4)\n",
    "test_dataset = torch.utils.data.TensorDataset(dataset.x[dataset.test_mask], dataset.y[dataset.test_mask])\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=64, shuffle=False, num_workers=4)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-15T23:19:53.884694Z",
     "start_time": "2023-10-15T23:19:53.881032Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    },
    {
     "data": {
      "text/plain": "42"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torchmetrics\n",
    "import os\n",
    "from torch import optim, nn, utils, Tensor\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision.transforms import ToTensor\n",
    "import pytorch_lightning as pl\n",
    "pl.seed_everything(42)\n",
    "from torchmetrics.classification import BinaryAUROC, BinaryAccuracy, BinaryF1Score\n",
    "\n",
    "\n",
    "# define the LightningModule\n",
    "class MLP(pl.LightningModule):\n",
    "    def __init__(self, num_features, hidden_channels, num_classes, criterion):\n",
    "        super().__init__()\n",
    "        self.lin1 = nn.Linear(num_features, hidden_channels)\n",
    "        self.lin2 = nn.Linear(hidden_channels, hidden_channels)\n",
    "        self.lin3 = nn.Linear(hidden_channels, num_classes)\n",
    "        self.criterion = criterion\n",
    "        \n",
    "        self.val_collection = torchmetrics.MetricCollection([BinaryAccuracy(), BinaryAUROC(), BinaryF1Score()])\n",
    "        self.test_collection = torchmetrics.MetricCollection([BinaryAccuracy(), BinaryAUROC(), BinaryF1Score()])\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.lin1(x)\n",
    "        x = x.relu()\n",
    "        x = self.lin2(x)\n",
    "        x = x.relu()\n",
    "        x = self.lin3(x)\n",
    "        return x\n",
    "\n",
    "    def get_auc(self, out, target):\n",
    "        return self.auroc(torch.sigmoid(out)[:, 1], target)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        logits = self(x)  # Perform a single forward pass.\n",
    "\n",
    "        loss = self.criterion(logits.squeeze(-1), y)  # Compute the loss solely based on the training nodes.\n",
    "        values = {\"loss\": loss}\n",
    "        self.log_dict(values, prog_bar=True)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        logits = self(x)  # Perform a single forward pass.\n",
    "        loss = self.criterion(logits.squeeze(-1), y)  # Compute the loss solely based on the training nodes.\n",
    "        \n",
    "        self.val_collection.update(logits.squeeze(-1), y)\n",
    "        self.log_dict(self.val_collection, prog_bar=True, on_step=False, on_epoch=True)\n",
    "        return loss\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        \n",
    "        loss = self.criterion(logits.squeeze(-1), y)\n",
    "        self.test_collection.update(logits.squeeze(-1), y)\n",
    "        self.log_dict(self.test_collection, prog_bar=True, on_step=False, on_epoch=True)\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = optim.Adam(self.parameters(), lr=1e-3)\n",
    "        return optimizer\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-15T23:19:54.435878Z",
     "start_time": "2023-10-15T23:19:54.427928Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "# init the autoencoder\n",
    "MLP_model = MLP(dataset.num_node_features, 10, 1, criterion = torch.nn.BCEWithLogitsLoss())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-15T23:19:55.267736Z",
     "start_time": "2023-10-15T23:19:55.232740Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name            | Type              | Params\n",
      "------------------------------------------------------\n",
      "0 | lin1            | Linear            | 20    \n",
      "1 | lin2            | Linear            | 110   \n",
      "2 | lin3            | Linear            | 11    \n",
      "3 | criterion       | BCEWithLogitsLoss | 0     \n",
      "4 | val_collection  | MetricCollection  | 0     \n",
      "5 | test_collection | MetricCollection  | 0     \n",
      "------------------------------------------------------\n",
      "141       Trainable params\n",
      "0         Non-trainable params\n",
      "141       Total params\n",
      "0.001     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "text/plain": "Sanity Checking: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c0b66cb2474c42458acf7ffdfa010192"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/cgu3/anaconda3/envs/grape-pi/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:436: Consider setting `persistent_workers=True` in 'val_dataloader' to speed up the dataloader worker initialization.\n",
      "/Users/cgu3/anaconda3/envs/grape-pi/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:436: Consider setting `persistent_workers=True` in 'train_dataloader' to speed up the dataloader worker initialization.\n"
     ]
    },
    {
     "data": {
      "text/plain": "Training: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "bd9af0e405ac420db09d5f58dd310fc4"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "6fce05fb0ca9463988bd64641b87abe2"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "6cf1ab76f3b64e56907daafca60993ea"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8eea14f1b43d40799fe808836f5fffea"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8a4c08c5343144a38b5679e621308e09"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f3dd131f877b41578fa82d0c314e3354"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e3e38e43229a4724a2891332e203623c"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8177336916574d27b940244b0b67b4df"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2cbbf9bf224e4dbabb9eb45f72d01b92"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "bf80dc3c552847e59b80b9eaa167bbb2"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "53a972ee63084d9cabc1510437128481"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "32171b9c5b8a43049e9bcc136fbd778f"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "47d3809728454ae3b4cd89c71dadfca0"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f9544a5640d346f59abe00a1c20ad120"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "22b944b251a74d5096c45cf63a47eaef"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c0cd2d54fc5e48039678ace25edd4429"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "34edc293a446441b869e51daba713a44"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3f0f653a75c64afeac9b0884d7a5e094"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "93ebdc9a759d4de68444deb612c0a045"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9b3ea5ea21d345f9b992f8383b05454c"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0e808b7ad40a4f8283c4c1786fae1307"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=20` reached.\n"
     ]
    }
   ],
   "source": [
    "trainer = pl.Trainer(max_epochs=20, enable_progress_bar = True)\n",
    "trainer.fit(model=MLP_model, train_dataloaders=train_dataloader, val_dataloaders=val_dataloader)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-15T23:20:58.657656Z",
     "start_time": "2023-10-15T23:19:55.842966Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "data": {
      "text/plain": "Testing: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "99dfe973fe434aefa869de98f0e46bad"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       BinaryAUROC           0.810944139957428\n",
      "     BinaryAccuracy         0.7554517388343811\n",
      "      BinaryF1Score         0.7065420746803284\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "text/plain": "[{'BinaryAccuracy': 0.7554517388343811,\n  'BinaryAUROC': 0.810944139957428,\n  'BinaryF1Score': 0.7065420746803284}]"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.test(model=MLP_model, dataloaders=test_dataloader)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-15T23:21:14.367046Z",
     "start_time": "2023-10-15T23:21:12.847019Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name            | Type              | Params\n",
      "------------------------------------------------------\n",
      "0 | lin1            | Linear            | 30    \n",
      "1 | lin2            | Linear            | 110   \n",
      "2 | lin3            | Linear            | 11    \n",
      "3 | criterion       | BCEWithLogitsLoss | 0     \n",
      "4 | val_collection  | MetricCollection  | 0     \n",
      "5 | test_collection | MetricCollection  | 0     \n",
      "------------------------------------------------------\n",
      "151       Trainable params\n",
      "0         Non-trainable params\n",
      "151       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "/Users/cgu3/opt/anaconda3/envs/Grape-Pi/lib/python3.10/site-packages/pytorch_lightning/loops/fit_loop.py:281: PossibleUserWarning: The number of training batches (41) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "  rank_zero_warn(\n",
      "`Trainer.fit` stopped: `max_epochs=20` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       BinaryAUROC            0.877685546875\n",
      "     BinaryAccuracy         0.8099688291549683\n",
      "      BinaryF1Score         0.7550200819969177\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "text/plain": "[{'BinaryAccuracy': 0.8099688291549683,\n  'BinaryAUROC': 0.877685546875,\n  'BinaryF1Score': 0.7550200819969177}]"
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%reload_ext tensorboard\n",
    "%tensorboard --logdir=lightning_logs/"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-10T03:49:43.232130Z",
     "start_time": "2023-10-10T03:47:35.649471Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from torch_geometric.nn import GCNConv\n",
    "import torch_geometric.nn as nn\n",
    "\n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self, num_node_features, hidden_channels, num_classes):\n",
    "        super().__init__()\n",
    "        torch.manual_seed(1234567)\n",
    "        self.conv1 = GCNConv(num_node_features, hidden_channels)\n",
    "        # self.batch_norm1 = nn.BatchNorm(hidden_channels)\n",
    "        self.conv2 = GCNConv(hidden_channels, num_classes)\n",
    "        # self.batch_norm2 = nn.BatchNorm(hidden_channels)\n",
    "\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = x.relu()\n",
    "        # use batchnorm instead of dropout\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        # x = self.batch_norm1(x)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return x\n",
    "\n",
    "model = GCN(num_node_features=dataset.num_node_features, hidden_channels=16, num_classes=2)\n",
    "print(model)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rebuilding...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive vs negative in train dataset: tensor([1431, 1136])\n",
      "Positive vs negative in val dataset: tensor([178, 143])\n",
      "Positive vs negative in test dataset: tensor([167, 154])\n",
      "Number of node features: 1\n",
      "Number of edge features: 0\n",
      "Number of training nodes: 2567\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# Install required packages.\n",
    "import os\n",
    "import torch\n",
    "os.environ['TORCH'] = torch.__version__\n",
    "print(torch.__version__)\n",
    "\n",
    "# uncomment for first time run\n",
    "# !pip install -q torch-scatter -f https://data.pyg.org/whl/torch-${TORCH}.html\n",
    "# !pip install -q torch-sparse -f https://data.pyg.org/whl/torch-${TORCH}.html\n",
    "# !pip install -q git+https://github.com/pyg-team/pytorch_geometric.git\n",
    "\n",
    "# Helper function for visualization.\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "def visualize(h, color):\n",
    "    z = TSNE(n_components=2).fit_transform(h.detach().cpu().numpy())\n",
    "\n",
    "    plt.figure(figsize=(10,10))\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "\n",
    "    plt.scatter(z[:, 0], z[:, 1], s=30, alpha=0.5, c=color, cmap=\"Set2\")\n",
    "    plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "end_time": "2023-10-10T03:49:44.690200Z",
     "start_time": "2023-10-10T03:49:43.237636Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name            | Type              | Params\n",
      "------------------------------------------------------\n",
      "0 | lin1            | Linear            | 20    \n",
      "1 | lin2            | Linear            | 110   \n",
      "2 | lin3            | Linear            | 11    \n",
      "3 | criterion       | BCEWithLogitsLoss | 0     \n",
      "4 | val_collection  | MetricCollection  | 0     \n",
      "5 | test_collection | MetricCollection  | 0     \n",
      "------------------------------------------------------\n",
      "141       Trainable params\n",
      "0         Non-trainable params\n",
      "141       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "/Users/cgu3/opt/anaconda3/envs/Grape-Pi/lib/python3.10/site-packages/pytorch_lightning/loops/fit_loop.py:281: PossibleUserWarning: The number of training batches (41) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "  rank_zero_warn(\n",
      "`Trainer.fit` stopped: `max_epochs=20` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       BinaryAUROC          0.6336417198181152\n",
      "     BinaryAccuracy         0.6230529546737671\n",
      "      BinaryF1Score         0.4265402853488922\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "text/plain": "[{'BinaryAccuracy': 0.6230529546737671,\n  'BinaryAUROC': 0.6336417198181152,\n  'BinaryF1Score': 0.4265402853488922}]"
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = GCN(num_node_features=dataset.num_node_features, hidden_channels=16, num_classes=2)\n",
    "model.eval()\n",
    "\n",
    "out = model(dataset.x, dataset.edge_index)\n",
    "visualize(out, color=dataset.y)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "end_time": "2023-10-10T03:51:50.405040Z",
     "start_time": "2023-10-10T03:49:44.692357Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from IPython.display import Javascript  # Restrict height of output cell.\n",
    "display(Javascript('''google.colab.output.setIframeHeight(0, true, {maxHeight: 300})'''))\n",
    "\n",
    "model = GCN(num_node_features=dataset.num_node_features, hidden_channels=10, num_classes=2)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=5e-4)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "def train():\n",
    "      model.train()\n",
    "      optimizer.zero_grad()  # Clear gradients.\n",
    "      out = model(dataset.x, dataset.edge_index)  # Perform a single forward pass.\n",
    "      train_loss = criterion(out[dataset.train_mask], dataset.y[dataset.train_mask])  # Compute the loss solely based on the training nodes.\n",
    "      pred = out.argmax(dim=1)  # Use the class with highest probability.\n",
    "      train_correct = pred[dataset.train_mask] == dataset.y[dataset.train_mask]  # Check against ground-truth labels.\n",
    "      train_acc = int(train_correct.sum()) / int(dataset.train_mask.sum())\n",
    "      train_loss.backward()  # Derive gradients.\n",
    "      optimizer.step()  # Update parameters based on gradients.\n",
    "      return float(train_loss.detach()), train_acc\n",
    "\n",
    "\n",
    "def val():\n",
    "      model.eval()\n",
    "      out = model(dataset.x, dataset.edge_index)\n",
    "      val_loss = criterion(out[dataset.val_mask], dataset.y[dataset.val_mask])\n",
    "      pred = out.argmax(dim=1)  # Use the class with highest probability.\n",
    "      val_correct = pred[dataset.val_mask] == dataset.y[dataset.val_mask] # Check against ground-truth labels.\n",
    "      val_acc = int(val_correct.sum()) / int(dataset.val_mask.sum())  # Derive ratio of correct predictions.\n",
    "      return float(val_loss.detach()), val_acc\n",
    "\n",
    "def test():\n",
    "      model.eval()\n",
    "      out = model(dataset.x, dataset.edge_index)\n",
    "      pred = out.argmax(dim=1)  # Use the class with highest probability.\n",
    "      test_correct = pred[dataset.test_mask] == dataset.y[dataset.test_mask]  # Check against ground-truth labels.\n",
    "      test_acc = int(test_correct.sum()) / int(dataset.test_mask.sum())  # Derive ratio of correct predictions.\n",
    "      return test_acc\n",
    "\n",
    "train_loss_history = []\n",
    "train_acc_history = []\n",
    "val_acc_history = []\n",
    "val_loss_history = []\n",
    "for epoch in range(1, 101):\n",
    "    train_loss, train_acc = train()\n",
    "    train_loss_history.append(train_loss)\n",
    "    train_acc_history.append(train_acc)\n",
    "    val_loss, val_acc = val()\n",
    "    val_loss_history.append(val_loss)\n",
    "    val_acc_history.append(val_acc)\n",
    "    print(f'Epoch: {epoch:03d}, Train loss: {train_loss:.4f} Train acc: {train_acc:.4f} '\n",
    "          f'Validation loss: {val_loss: .4f}, Validation acc: {val_acc:.4f}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rebuilding...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive vs negative in train dataset: tensor([1439, 1128])\n",
      "Positive vs negative in val dataset: tensor([159, 162])\n",
      "Positive vs negative in test dataset: tensor([178, 143])\n",
      "Number of node features: 2\n",
      "Number of edge features: 0\n",
      "Number of training nodes: 2567\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "plt.plot(train_loss_history)\n",
    "plt.plot(val_loss_history)\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper right')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(train_acc_history)\n",
    "plt.plot(val_acc_history)\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('acc')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper right')\n",
    "plt.show()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "end_time": "2023-10-10T03:51:51.793781Z",
     "start_time": "2023-10-10T03:51:50.411709Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name            | Type              | Params\n",
      "------------------------------------------------------\n",
      "0 | lin1            | Linear            | 30    \n",
      "1 | lin2            | Linear            | 110   \n",
      "2 | lin3            | Linear            | 11    \n",
      "3 | criterion       | BCEWithLogitsLoss | 0     \n",
      "4 | val_collection  | MetricCollection  | 0     \n",
      "5 | test_collection | MetricCollection  | 0     \n",
      "------------------------------------------------------\n",
      "151       Trainable params\n",
      "0         Non-trainable params\n",
      "151       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       BinaryAUROC           0.81549072265625\n",
      "     BinaryAccuracy          0.732087254524231\n",
      "      BinaryF1Score         0.6884058117866516\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "text/plain": "[{'BinaryAccuracy': 0.732087254524231,\n  'BinaryAUROC': 0.81549072265625,\n  'BinaryF1Score': 0.6884058117866516}]"
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_acc = test()\n",
    "print(f'Test Accuracy: {test_acc:.4f}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "end_time": "2023-10-10T04:01:05.213047Z",
     "start_time": "2023-10-10T03:55:57.078103Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model.eval()\n",
    "\n",
    "out = model(dataset.x, dataset.edge_index)\n",
    "visualize(out, color=dataset.y)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "end_time": "2023-10-10T03:22:10.608167Z",
     "start_time": "2023-10-10T03:22:10.601841Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# when dataset contain two graph\n",
    "# to-do create dataset class\n",
    "\n",
    "\n",
    "# need good standardization to generalize to model to different spices and experiment conditions\n",
    "# semi-supervise\n",
    "# transfer learning\n",
    "\n",
    "\n",
    "# the performance is not good\n",
    "# need to include more nodes features: protein characteristics, ...\n",
    "# more ideal not use calculated protein score, instead use variables used to calculate protein score directly\n",
    "\n",
    "\n",
    "\n",
    "# GPU resource"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
