{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "end_time": "2023-10-17T16:01:56.939350Z",
     "start_time": "2023-10-17T16:01:56.884045Z"
    }
   },
   "outputs": [],
   "source": [
    "# %connect_info\n",
    "%qtconsole"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-17T16:28:21.479988Z",
     "start_time": "2023-10-17T16:28:18.708820Z"
    }
   },
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from graphgym.custom_graphgym.loader.protein import ProteinDataset\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-17T16:28:21.484125Z",
     "start_time": "2023-10-17T16:28:21.481176Z"
    }
   },
   "outputs": [],
   "source": [
    "os.chdir('/Users/cgu3/Documents/Grape-Pi')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-12T03:03:24.211502Z",
     "start_time": "2023-10-12T03:03:23.909922Z"
    },
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Import data from csv fies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-17T16:28:37.332566Z",
     "start_time": "2023-10-17T16:28:37.319425Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# dataset = ProteinDataset(\"data/yeast-ORBI\", numeric_columns=['protein probability'], label_column=None)\n",
    "# dataset = ProteinBatchDataset(\"data/yeast-LCQ\", numeric_params=['protein probability'])\n",
    "# dataset = ProteinBatchDataset(\"data/yeast-ORBI-mRNA\", numeric_params=['protein probability', 'mRNA(M)'])\n",
    "# dataset = ProteinBatchDataset(\"data/yeast-LCQ-mRNA\", numeric_params=['protein probability', 'mRNA(M)'])\n",
    "# dataset = ProteinDataset(\"data/single-soft-label\", numeric_columns=['protein_probability', 'mRNA_TPM'], label_column=None)\n",
    "protein_dataset = ProteinDataset(\"data/single\", numeric_columns=['protein_probability'], label_column=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-17T16:28:44.479319Z",
     "start_time": "2023-10-17T16:28:44.467045Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "      protein.Accession  protein_probability  protein_probability_soft_label  \\\n0            A0A075B6H7             0.700122                        0.267383   \n1            A0A075B6H8             0.286947                        0.056265   \n2            A0A075B6L6             0.943529                        0.140940   \n3            A0A075B6N1             0.289680                        0.153119   \n4            A0A075B6N2             0.259341                        0.128836   \n...                 ...                  ...                             ...   \n12532            Q9UI54             0.000000                        0.000000   \n12533            Q9Y3F1             0.000000                        0.197423   \n12534            Q9Y6C7             0.000000                        0.093179   \n12535            Q9Y6Z2             0.000000                        0.000000   \n12536            X6R8R1             0.000000                        0.283767   \n\n       hard_label gene_symbol  mRNA_TPM  \n0               0     IGKV3-7  0.000000  \n1               0   IGKV1D-42  0.000000  \n2               0     TRBV7-3  0.000000  \n3               0      TRBV19  0.000000  \n4               0    TRBV20-1  0.370502  \n...           ...         ...       ...  \n12532           0           0  0.000000  \n12533           0           0  0.000000  \n12534           0   LINC00312  0.000000  \n12535           0   LINC01558  0.053100  \n12536           0      SYT15B  0.000000  \n\n[12537 rows x 6 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>protein.Accession</th>\n      <th>protein_probability</th>\n      <th>protein_probability_soft_label</th>\n      <th>hard_label</th>\n      <th>gene_symbol</th>\n      <th>mRNA_TPM</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>A0A075B6H7</td>\n      <td>0.700122</td>\n      <td>0.267383</td>\n      <td>0</td>\n      <td>IGKV3-7</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>A0A075B6H8</td>\n      <td>0.286947</td>\n      <td>0.056265</td>\n      <td>0</td>\n      <td>IGKV1D-42</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>A0A075B6L6</td>\n      <td>0.943529</td>\n      <td>0.140940</td>\n      <td>0</td>\n      <td>TRBV7-3</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>A0A075B6N1</td>\n      <td>0.289680</td>\n      <td>0.153119</td>\n      <td>0</td>\n      <td>TRBV19</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>A0A075B6N2</td>\n      <td>0.259341</td>\n      <td>0.128836</td>\n      <td>0</td>\n      <td>TRBV20-1</td>\n      <td>0.370502</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>12532</th>\n      <td>Q9UI54</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>12533</th>\n      <td>Q9Y3F1</td>\n      <td>0.000000</td>\n      <td>0.197423</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>12534</th>\n      <td>Q9Y6C7</td>\n      <td>0.000000</td>\n      <td>0.093179</td>\n      <td>0</td>\n      <td>LINC00312</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>12535</th>\n      <td>Q9Y6Z2</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0</td>\n      <td>LINC01558</td>\n      <td>0.053100</td>\n    </tr>\n    <tr>\n      <th>12536</th>\n      <td>X6R8R1</td>\n      <td>0.000000</td>\n      <td>0.283767</td>\n      <td>0</td>\n      <td>SYT15B</td>\n      <td>0.000000</td>\n    </tr>\n  </tbody>\n</table>\n<p>12537 rows × 6 columns</p>\n</div>"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "protein_file = [f for f in os.listdir('data/single/raw/protein') if f.endswith('.csv')][0]\n",
    "df = pd.read_csv(os.path.join('data/single/raw/protein', protein_file))\n",
    "ids = df['protein.Accession'].values\n",
    "# df = pd.read_csv('/Users/cgu3/Documents/data/SG_combined_protein_0982_with_protein_probability.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-17T16:28:49.093380Z",
     "start_time": "2023-10-17T16:28:49.091522Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, data, labels, ids, train_mask=None, val_mask=None, test_mask=None):\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "        self.ids = ids\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        sample_data = self.data[index]\n",
    "        sample_label = self.labels[index]\n",
    "        sample_id = self.ids[index]\n",
    "        return sample_data, sample_label, sample_id\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-17T16:28:55.571904Z",
     "start_time": "2023-10-17T16:28:55.567909Z"
    }
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, Subset\n",
    "dataset = CustomDataset(protein_dataset.x, protein_dataset.y, ids)\n",
    "\n",
    "train_indices = torch.nonzero(protein_dataset.train_mask).squeeze().tolist()\n",
    "train_dataset = Subset(dataset, train_indices)\n",
    "\n",
    "val_indices = torch.nonzero(protein_dataset.val_mask).squeeze().tolist()\n",
    "val_dataset = Subset(dataset, val_indices)\n",
    "\n",
    "test_indices = torch.nonzero(protein_dataset.test_mask).squeeze().tolist()\n",
    "test_dataset = Subset(dataset, test_indices)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "data": {
      "text/plain": "(tensor([0.9959, 3.9471]), tensor(1.), 'A0A075B6N1')"
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[1]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-17T16:29:37.909315Z",
     "start_time": "2023-10-17T16:29:37.905561Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-17T16:29:43.241322Z",
     "start_time": "2023-10-17T16:29:43.231703Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<torch._C.Generator at 0x1696ccd70>"
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "torch.manual_seed(12345)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=64, shuffle=False)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 2])\n",
      "torch.Size([64])\n",
      "('Q86TB9', 'P34995', 'P55265', 'Q5VSR9', 'Q86XA0', 'Q8IZF5', 'Q2M243', 'P20073', 'Q96BA8', 'P43681', 'P17858', 'Q8TDQ7', 'P50749', 'P54259', 'Q9BX73', 'Q96NK8', 'Q8IYI6', 'Q00839', 'Q13243', 'Q16880', 'Q92945', 'Q96PL1', 'Q8TEQ8', 'O14910', 'P49796', 'P0DME0', 'P13646', 'P05771', 'O60216', 'P56192', 'Q9BXL8', 'P17931', 'Q12972', 'Q8N3J5', 'Q15042', 'Q7Z7H3', 'Q68G75', 'Q8N2E6', 'Q96AE4', 'Q96AZ6', 'Q8TEV8', 'Q8IZM8', 'Q6PJT7', 'O60907', 'P00558', 'Q6IAN0', 'P31939', 'Q8NGB8', 'P00505', 'Q9BS26', 'Q8TF32', 'O75311', 'O75116', 'O15344', 'P01877', 'Q14739', 'Q5SY13', 'Q8IYK2', 'P18124', 'Q7KZF4', 'Q8IWX8', 'O15305', 'P23381', 'Q3KQU3')\n"
     ]
    }
   ],
   "source": [
    "for batch in train_dataloader:\n",
    "    x, y, id = batch\n",
    "    print(x.shape)\n",
    "    print(y.shape)\n",
    "    print(id)\n",
    "    break"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-17T16:29:52.319369Z",
     "start_time": "2023-10-17T16:29:52.310169Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-17T16:30:24.734365Z",
     "start_time": "2023-10-17T16:30:24.732630Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from torch import optim, nn, utils, Tensor\n",
    "import pytorch_lightning as pl\n",
    "from torchmetrics.classification import BinaryAUROC, BinaryAccuracy, BinaryF1Score\n",
    "import torch\n",
    "\n",
    "\n",
    "# define the LightningModule\n",
    "class MLP(pl.LightningModule):\n",
    "    def __init__(self, num_features, hidden_channels, num_classes, criterion):\n",
    "        super().__init__()\n",
    "        torch.manual_seed(12345)\n",
    "        self.lin1 = nn.Linear(num_features, hidden_channels)\n",
    "        self.lin2 = nn.Linear(hidden_channels, num_classes)\n",
    "        # self.lin3 = nn.Linear(hidden_channels, num_classes)\n",
    "        self.criterion = criterion\n",
    "        self.val_auroc = BinaryAUROC()\n",
    "        self.test_auroc = BinaryAUROC()\n",
    "        self.val_accuracy = BinaryAccuracy()\n",
    "        self.test_accuracy = BinaryAccuracy()\n",
    "        self.val_F1 = BinaryF1Score()\n",
    "        self.test_F1 = BinaryF1Score()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.lin1(x)\n",
    "        x = x.relu()\n",
    "        x = self.lin2(x)\n",
    "        return x\n",
    "\n",
    "    def get_auc(self, out, target):\n",
    "        return self.auroc(out, target)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y, id = batch\n",
    "        logits = self(x).squeeze(-1)  # Perform a single forward pass.\n",
    "\n",
    "        loss = self.criterion(logits, y)  # Compute the loss solely based on the training nodes.\n",
    "        values = {\"loss\": loss}\n",
    "        self.log_dict(values, prog_bar=True)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y, ids = batch\n",
    "        logits = self(x).squeeze(-1)  # Perform a single forward pass.\n",
    "        self.val_accuracy.update(logits, y)\n",
    "        loss = self.criterion(logits, y)  # Compute the loss solely based on the training nodes.\n",
    "        self.val_auroc.update(logits, y)\n",
    "        self.val_F1.update(logits, y)\n",
    "        values = {\"val_loss\": loss, \"val_acc\": self.val_accuracy, \"val_auroc\": self.val_auroc, \"val_F1\": self.val_F1}\n",
    "        self.log_dict(values, prog_bar=True, on_step=False, on_epoch=True)\n",
    "        return loss\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        x, y, ids = batch\n",
    "        logits = self(x).squeeze(-1)\n",
    "        self.test_accuracy.update(logits, y)\n",
    "        loss = self.criterion(logits, y)\n",
    "        self.test_auroc.update(logits, y)\n",
    "        self.test_F1.update(logits, y)\n",
    "        values = {\"test_loss\": loss, \"test_acc\": self.test_accuracy, \"test_auroc\": self.test_auroc, \"test_F1\": self.test_F1}\n",
    "        self.log_dict(values, prog_bar=True, on_step=False, on_epoch=True)\n",
    "        return loss\n",
    "    \n",
    "    def predict_step(self, batch, batch_idx):\n",
    "        x, y, ids = batch\n",
    "        ids = [item for sublist in ids for item in sublist]\n",
    "        logits = self(x).squeeze(-1)\n",
    "        pred_prob = torch.nn.functional.sigmoid(logits)\n",
    "        return (ids, x[:, 0], x[:, 1], pred_prob, y)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = optim.Adam(self.parameters(), lr=1e-3)\n",
    "        return optimizer\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-17T16:30:25.118114Z",
     "start_time": "2023-10-17T16:30:25.110797Z"
    }
   },
   "outputs": [],
   "source": [
    "# init the autoencoder\n",
    "MLP_model = MLP(2, 10, 1, criterion = torch.nn.BCEWithLogitsLoss())\n",
    "# MLP_model = MLP(dataset.num_node_features, 10, 2, criterion = torch.nn.CrossEntropyLoss())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-17T16:30:26.071172Z",
     "start_time": "2023-10-17T16:30:26.063771Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "from pytorch_lightning.callbacks import TQDMProgressBar\n",
    "\n",
    "\n",
    "class MyProgressBar(TQDMProgressBar):\n",
    "    def init_validation_tqdm(self):\n",
    "        bar = super().init_validation_tqdm()\n",
    "        if not sys.stdout.isatty():\n",
    "            bar.disable = True\n",
    "        return bar\n",
    "\n",
    "    def init_predict_tqdm(self):\n",
    "        bar = super().init_predict_tqdm()\n",
    "        if not sys.stdout.isatty():\n",
    "            bar.disable = True\n",
    "        return bar\n",
    "\n",
    "    def init_test_tqdm(self):\n",
    "        bar = super().init_test_tqdm()\n",
    "        if not sys.stdout.isatty():\n",
    "            bar.disable = True\n",
    "        return bar\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-17T16:30:48.740124Z",
     "start_time": "2023-10-17T16:30:48.720302Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "import pytorch_lightning as pl\n",
    "trainer = pl.Trainer(max_epochs=100, enable_progress_bar=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-17T16:31:15.899971Z",
     "start_time": "2023-10-17T16:30:49.312346Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name          | Type              | Params\n",
      "----------------------------------------------------\n",
      "0 | lin1          | Linear            | 30    \n",
      "1 | lin2          | Linear            | 11    \n",
      "2 | criterion     | BCEWithLogitsLoss | 0     \n",
      "3 | val_auroc     | BinaryAUROC       | 0     \n",
      "4 | test_auroc    | BinaryAUROC       | 0     \n",
      "5 | val_accuracy  | BinaryAccuracy    | 0     \n",
      "6 | test_accuracy | BinaryAccuracy    | 0     \n",
      "7 | val_F1        | BinaryF1Score     | 0     \n",
      "8 | test_F1       | BinaryF1Score     | 0     \n",
      "----------------------------------------------------\n",
      "41        Trainable params\n",
      "0         Non-trainable params\n",
      "41        Total params\n",
      "0.000     Total estimated model params size (MB)\n",
      "/Users/cgu3/anaconda3/envs/grape-pi/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n",
      "/Users/cgu3/anaconda3/envs/grape-pi/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n",
      "/Users/cgu3/anaconda3/envs/grape-pi/lib/python3.10/site-packages/pytorch_lightning/loops/fit_loop.py:293: The number of training batches (47) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n"
     ]
    }
   ],
   "source": [
    "trainer.fit(model=MLP_model, train_dataloaders=train_dataloader, val_dataloaders=val_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-17T16:31:16.061033Z",
     "start_time": "2023-10-17T16:31:15.901072Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "         test_F1            0.9259938597679138\n",
      "        test_acc            0.8770325183868408\n",
      "       test_auroc           0.9030500650405884\n",
      "        test_loss           0.29189321398735046\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/cgu3/anaconda3/envs/grape-pi/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "text/plain": "[{'test_loss': 0.29189321398735046,\n  'test_acc': 0.8770325183868408,\n  'test_auroc': 0.9030500650405884,\n  'test_F1': 0.9259938597679138}]"
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.test(model=MLP_model, dataloaders=test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-16T21:46:36.022187Z",
     "start_time": "2023-10-16T21:46:35.936187Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "out = trainer.predict(MLP_model, dataloaders=test_dataloader)\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-12T02:34:30.613594Z",
     "start_time": "2023-10-12T02:34:14.340022Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "accession, raw_prob, mRNA, pred_prob, soft_label = zip(*out)\n",
    "accession = [item for sublist in accession for item in sublist]\n",
    "raw_prob = [item.item() for sublist in raw_prob for item in sublist]\n",
    "mRNA = [item.item() for sublist in mRNA for item in sublist]\n",
    "pred_prob = [item.item() for sublist in pred_prob for item in sublist]\n",
    "soft_label = [item.item() for sublist in soft_label for item in sublist]\n",
    "pd.DataFrame({'accession': accession, 'raw_prob': raw_prob, 'mRNA': mRNA, 'pred_prob': pred_prob, 'soft_label': soft_label})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-04T19:24:41.068889Z",
     "start_time": "2023-10-04T19:24:40.966076Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-22T21:19:13.658811Z",
     "start_time": "2023-09-22T21:19:09.970212Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%reload_ext tensorboard\n",
    "%tensorboard --logdir=lightning_logs/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
