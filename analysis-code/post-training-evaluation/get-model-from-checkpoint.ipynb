{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 77,
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "os.chdir('/Users/cgu3/Documents/Grape-Pi/graphgym')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-04T18:43:31.329934Z",
     "start_time": "2023-10-04T18:43:31.322058Z"
    }
   },
   "id": "8a5ae1a96c94632d"
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-10-04T18:13:59.197348Z",
     "start_time": "2023-10-04T18:13:25.129755Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GraphsageGraphGymModule(\n",
      "  (model): GNN(\n",
      "    (encoder): FeatureEncoder()\n",
      "    (pre_mp): GeneralMultiLayer(\n",
      "      (Layer_0): GeneralLayer(\n",
      "        (layer): Linear(\n",
      "          (model): Linear(2, 10, bias=True)\n",
      "        )\n",
      "        (post_layer): Sequential(\n",
      "          (0): ReLU()\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (mp): GNNStackStage(\n",
      "      (layer0): GeneralLayer(\n",
      "        (layer): SAGEConv(\n",
      "          (model): SAGEConv(10, 10, aggr=mean)\n",
      "        )\n",
      "        (post_layer): Sequential(\n",
      "          (0): ReLU()\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (post_mp): ExampleNodeHead(\n",
      "      (layer_post_mp): MLP(\n",
      "        (model): Sequential(\n",
      "          (0): Linear(\n",
      "            (model): Linear(10, 1, bias=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "accelerator: cpu\n",
      "benchmark: False\n",
      "bn:\n",
      "  eps: 1e-05\n",
      "  mom: 0.1\n",
      "cfg_dest: config.yaml\n",
      "custom_metrics: []\n",
      "dataset:\n",
      "  cache_load: False\n",
      "  cache_save: False\n",
      "  dir: ../data/single-soft-label\n",
      "  edge_dim: 128\n",
      "  edge_encoder: False\n",
      "  edge_encoder_bn: True\n",
      "  edge_encoder_name: Bond\n",
      "  edge_message_ratio: 0.8\n",
      "  edge_negative_sampling_ratio: 1.0\n",
      "  edge_train_mode: all\n",
      "  encoder: False\n",
      "  encoder_bn: True\n",
      "  encoder_dim: 128\n",
      "  encoder_name: db\n",
      "  format: PyG\n",
      "  label_column: protein_probability_soft_label\n",
      "  label_table: none\n",
      "  location: local\n",
      "  name: protein\n",
      "  node_encoder: False\n",
      "  node_encoder_bn: True\n",
      "  node_encoder_name: Atom\n",
      "  numeric_columns: ['protein_probability', 'mRNA_TPM']\n",
      "  remove_feature: False\n",
      "  resample_disjoint: False\n",
      "  resample_negative: False\n",
      "  shuffle_split: True\n",
      "  split: [0.6, 0.2, 0.2]\n",
      "  split_mode: random\n",
      "  task: node\n",
      "  task_type: classification_binary_soft_label\n",
      "  to_undirected: False\n",
      "  transductive: False\n",
      "  transform: none\n",
      "  tu_simple: True\n",
      "devices: None\n",
      "gnn:\n",
      "  act: relu\n",
      "  agg: add\n",
      "  att_final_linear: False\n",
      "  att_final_linear_bn: False\n",
      "  att_heads: 1\n",
      "  batchnorm: False\n",
      "  clear_feature: True\n",
      "  dim_inner: 10\n",
      "  dropout: 0.0\n",
      "  head: protein\n",
      "  keep_edge: 0.5\n",
      "  l2norm: True\n",
      "  layer_type: sageconv\n",
      "  layers_mp: 1\n",
      "  layers_post_mp: 1\n",
      "  layers_pre_mp: 1\n",
      "  msg_direction: single\n",
      "  normalize_adj: False\n",
      "  self_msg: concat\n",
      "  skip_every: 1\n",
      "  stage_type: skipsum\n",
      "gpu_mem: False\n",
      "mem:\n",
      "  inplace: False\n",
      "metric_agg: argmax\n",
      "metric_best: auc\n",
      "model:\n",
      "  edge_decoding: dot\n",
      "  graph_pooling: add\n",
      "  loss_fun: cross_entropy\n",
      "  match_upper: True\n",
      "  size_average: mean\n",
      "  thresh: 0.5\n",
      "  type: gnn\n",
      "num_threads: 6\n",
      "num_workers: 8\n",
      "optim:\n",
      "  base_lr: 0.001\n",
      "  lr_decay: 0.1\n",
      "  max_epoch: 100\n",
      "  momentum: 0.9\n",
      "  optimizer: adam\n",
      "  scheduler: none\n",
      "  steps: [30, 60, 90]\n",
      "  weight_decay: 0.0005\n",
      "out_dir: results\n",
      "params: 251\n",
      "print: both\n",
      "round: 4\n",
      "run_dir: results\n",
      "seed: 0\n",
      "share:\n",
      "  dim_in: 2\n",
      "  dim_out: 1\n",
      "  num_splits: 3\n",
      "tensorboard_agg: True\n",
      "tensorboard_each_run: False\n",
      "train:\n",
      "  auto_resume: False\n",
      "  batch_size: 128\n",
      "  ckpt_clean: False\n",
      "  ckpt_period: 10\n",
      "  enable_ckpt: True\n",
      "  epoch_resume: 0\n",
      "  eval_period: 10\n",
      "  grape_pi: graphsage\n",
      "  iter_per_epoch: 32\n",
      "  loss_pos_weight: 783.0\n",
      "  neighbor_sizes: [20, 10, 5]\n",
      "  node_per_graph: 32\n",
      "  radius: extend\n",
      "  sample_node: False\n",
      "  sampler: neighbor\n",
      "  skip_train_eval: False\n",
      "  walk_length: 4\n",
      "val:\n",
      "  node_per_graph: 32\n",
      "  radius: extend\n",
      "  sample_node: False\n",
      "  sampler: full_batch\n",
      "view_emb: False\n",
      "Num parameters: 251\n"
     ]
    },
    {
     "data": {
      "text/plain": "<All keys matched successfully>"
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import logging\n",
    "\n",
    "import graphgym.custom_graphgym # noqa, register custom modules\n",
    "import torch\n",
    "from torch_geometric import seed_everything\n",
    "import argparse\n",
    "from torch_geometric.graphgym.config import (\n",
    "    cfg,\n",
    "    dump_cfg,\n",
    "    load_cfg,\n",
    "    set_out_dir,\n",
    "    set_run_dir,\n",
    ")\n",
    "from torch_geometric.graphgym.model_builder import create_model\n",
    "from torch_geometric.graphgym.register import train_dict\n",
    "from torch_geometric.graphgym.train import GraphGymDataModule, train\n",
    "from torch_geometric.graphgym.utils.agg_runs import agg_runs\n",
    "from torch_geometric.graphgym.utils.comp_budget import params_count\n",
    "from torch_geometric.graphgym.utils.device import auto_select_device\n",
    "\n",
    "from graphgym import logger\n",
    "import shlex\n",
    "\n",
    "parser = argparse.ArgumentParser(description='GraphGym')\n",
    "parser.add_argument('--cfg', dest='cfg_file', type=str, required=True,\n",
    "                    help='The configuration file path.')\n",
    "parser.add_argument('--repeat', type=int, default=1,\n",
    "                    help='The number of repeated jobs.')\n",
    "parser.add_argument('--mark_done', action='store_true',\n",
    "                    help='Mark yaml as done after a job has finished.')\n",
    "parser.add_argument('opts', default=None, nargs=argparse.REMAINDER,\n",
    "                    help='See graphgym/config.py for remaining options.')\n",
    "\n",
    "\n",
    "\n",
    "# Load cmd line args\n",
    "args = parser.parse_args(shlex.split('--cfg configs/protein/gastric-graphsage-soft-label.yaml'))\n",
    "# Load config file\n",
    "load_cfg(cfg, args)\n",
    "# Set Pytorch environment\n",
    "torch.set_num_threads(cfg.num_threads)\n",
    "# Repeat for different random seeds\n",
    "logger.set_printing()\n",
    "\n",
    "seed_everything(cfg.seed)\n",
    "auto_select_device()\n",
    "# Set machine learning pipeline\n",
    "\n",
    "model, datamodule = None, None\n",
    "# use the right customized datamodule and graphgymmodule\n",
    "if cfg.train.grape_pi == 'graphsage':\n",
    "    datamodule = train_dict['graphsage_graphgym_datamodule']()\n",
    "    model = train_dict['graphsage_create_model']()\n",
    "    # train = train_dict['graphsage_train']\n",
    "elif cfg.train.grape_pi == 'gcnconv':\n",
    "    datamodule = GraphGymDataModule()\n",
    "    model = train_dict['gcnconv_create_model']()\n",
    "    # train = train_dict['gcnconv_train']\n",
    "\n",
    "data_batch = next(iter(datamodule.loaders[0]))\n",
    "mapping = data_batch.mapping\n",
    "model(data_batch)\n",
    "\n",
    "# Print model info\n",
    "logging.info(model)\n",
    "logging.info(cfg)\n",
    "cfg.params = params_count(model)\n",
    "logging.info('Num parameters: %s', cfg.params)\n",
    "\n",
    "model.load_state_dict(torch.load('/Volumes/cgu3/graph-neural-network/saved_results/gastric-graphsage-soft-label-with-mRNA/0/ckpt/epoch=99-step=9600.ckpt')['state_dict'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "outputs": [
    {
     "data": {
      "text/plain": "{0: 'A0A024RBG1',\n 1: 'A0A075B6H7',\n 2: 'A0A075B6H8',\n 3: 'A0A075B6L6',\n 4: 'A0A075B6N1',\n 5: 'A0A075B6N2',\n 6: 'A0A075B6N3',\n 7: 'A0A075B6R0',\n 8: 'A0A075B6S4',\n 9: 'A0A075B759',\n 10: 'A0A087WSY6',\n 11: 'A0A087WUL8',\n 12: 'A0A087WUV0',\n 13: 'A0A087X0M5',\n 14: 'A0A087X1C5',\n 15: 'A0A096LP49',\n 16: 'A0A096LP55',\n 17: 'A0A096LPI5',\n 18: 'A0A0A0MS06',\n 19: 'A0A0A0MS15',\n 20: 'A0A0A0MT36',\n 21: 'A0A0A6YYL3',\n 22: 'A0A0B4J1V1',\n 23: 'A0A0B4J1V2',\n 24: 'A0A0B4J1X5',\n 25: 'A0A0B4J1X8',\n 26: 'A0A0B4J268',\n 27: 'A0A0B4J2D5',\n 28: 'A0A0C4DH24',\n 29: 'A0A0C4DH31',\n 30: 'A0A0C4DH32',\n 31: 'A0A0C4DH33',\n 32: 'A0A0C4DH38',\n 33: 'A0A0C4DH42',\n 34: 'A0A0C4DH55',\n 35: 'A0A0G2JMD5',\n 36: 'A0A0G2JMI3',\n 37: 'A0A0J9YVY3',\n 38: 'A0A0J9YWL9',\n 39: 'A0A0J9YX94',\n 40: 'A0A0J9YXV3',\n 41: 'A0A0J9YXX1',\n 42: 'A0A0U1RQS6',\n 43: 'A0A0U1RRI6',\n 44: 'A0A1B0GTU1',\n 45: 'A0A1B0GTY4',\n 46: 'A0A1B0GU33',\n 47: 'A0A1B0GUA5',\n 48: 'A0A1B0GUS4',\n 49: 'A0A1B0GUU1',\n 50: 'A0A1B0GUV1',\n 51: 'A0A1B0GUW6',\n 52: 'A0A1B0GV03',\n 53: 'A0A1B0GV85',\n 54: 'A0A1B0GV96',\n 55: 'A0A1B0GVG6',\n 56: 'A0A1B0GVH4',\n 57: 'A0A1B0GVH6',\n 58: 'A0A1B0GVH7',\n 59: 'A0A1B0GVM6',\n 60: 'A0A1B0GVN3',\n 61: 'A0A1B0GVZ2',\n 62: 'A0A1B0GW35',\n 63: 'A0A1B0GXF2',\n 64: 'A0A1W2PPH5',\n 65: 'A0A1W2PPK0',\n 66: 'A0A1W2PPM1',\n 67: 'A0A1W2PPW3',\n 68: 'A0A1W2PQ09',\n 69: 'A0A1W2PQ72',\n 70: 'A0A1W2PQL4',\n 71: 'A0A1W2PR95',\n 72: 'A0A1W2PRP0',\n 73: 'A0A286YF18',\n 74: 'A0A2R8Y2Y2',\n 75: 'A0A2R8Y4L2',\n 76: 'A0A2R8Y619',\n 77: 'A0A2R8YFL7',\n 78: 'A0A494C071',\n 79: 'A0A494C086',\n 80: 'A0A494C0N9',\n 81: 'A0A494C0Y3',\n 82: 'A0A494C0Z2',\n 83: 'A0A494C191',\n 84: 'A0A494C1R9',\n 85: 'A0A539',\n 86: 'A0A578',\n 87: 'A0A590UK83',\n 88: 'A0A8I5KQE6',\n 89: 'A0AUZ9',\n 90: 'A0AV02',\n 91: 'A0AVF1',\n 92: 'A0AVI2',\n 93: 'A0AVT1',\n 94: 'A0FGR8',\n 95: 'A0FGR9',\n 96: 'A0JNW5',\n 97: 'A0JP26',\n 98: 'A0M8Q6',\n 99: 'A0MZ66',\n 100: 'A0PG75',\n 101: 'A0PJX0',\n 102: 'A1A4G5',\n 103: 'A1A4S6',\n 104: 'A1A4V9',\n 105: 'A1A519',\n 106: 'A1A5C7',\n 107: 'A1A5D9',\n 108: 'A1IGU5',\n 109: 'A1KZ92',\n 110: 'A1L020',\n 111: 'A1L162',\n 112: 'A1L188',\n 113: 'A1L390',\n 114: 'A1L443',\n 115: 'A1L453',\n 116: 'A1L4H1',\n 117: 'A1L4K1',\n 118: 'A1X283',\n 119: 'A1YPR0',\n 120: 'A2A2Z9',\n 121: 'A2A3K4',\n 122: 'A2A3L6',\n 123: 'A2A3N6',\n 124: 'A2AJT9',\n 125: 'A2CJ06',\n 126: 'A2PYH4',\n 127: 'A2RRH5',\n 128: 'A2RRP1',\n 129: 'A2RTX5',\n 130: 'A2RTY3',\n 131: 'A2RU30',\n 132: 'A2RU48',\n 133: 'A2RU49',\n 134: 'A2RU54',\n 135: 'A2RUB1',\n 136: 'A2RUC4',\n 137: 'A2RUH7',\n 138: 'A2RUR9',\n 139: 'A2RUS2',\n 140: 'A2RUT3',\n 141: 'A2VCK2',\n 142: 'A2VDJ0',\n 143: 'A2VEC9',\n 144: 'A3KMH1',\n 145: 'A3KN83',\n 146: 'A3QJZ6',\n 147: 'A4D0S4',\n 148: 'A4D0V7',\n 149: 'A4D126',\n 150: 'A4D1B5',\n 151: 'A4D1E1',\n 152: 'A4D1F6',\n 153: 'A4D1P6',\n 154: 'A4D1T9',\n 155: 'A4D1U4',\n 156: 'A4D256',\n 157: 'A4D263',\n 158: 'A4D2H0',\n 159: 'A4D2P6',\n 160: 'A4FU01',\n 161: 'A4FU28',\n 162: 'A4FU49',\n 163: 'A4FU69',\n 164: 'A4GXA9',\n 165: 'A4UGR9',\n 166: 'A5A3E0',\n 167: 'A5D8V7',\n 168: 'A5D8W1',\n 169: 'A5PKW4',\n 170: 'A5PL33',\n 171: 'A5PLK6',\n 172: 'A5PLN7',\n 173: 'A5PLN9',\n 174: 'A5YKK6',\n 175: 'A5YM69',\n 176: 'A5YM72',\n 177: 'A6H8Y1',\n 178: 'A6NC57',\n 179: 'A6NC78',\n 180: 'A6NC98',\n 181: 'A6NCI4',\n 182: 'A6NCM1',\n 183: 'A6NCN2',\n 184: 'A6NCQ9',\n 185: 'A6NCS6',\n 186: 'A6NCW7',\n 187: 'A6ND36',\n 188: 'A6ND91',\n 189: 'A6NDB9',\n 190: 'A6NDE4',\n 191: 'A6NDG6',\n 192: 'A6NDH6',\n 193: 'A6NDK9',\n 194: 'A6NDN3',\n 195: 'A6NDY0',\n 196: 'A6NDY2',\n 197: 'A6NE01',\n 198: 'A6NE52',\n 199: 'A6NEC2',\n 200: 'A6NED2',\n 201: 'A6NEK1',\n 202: 'A6NEQ0',\n 203: 'A6NES4',\n 204: 'A6NEV1',\n 205: 'A6NF34',\n 206: 'A6NFA0',\n 207: 'A6NFA1',\n 208: 'A6NFE2',\n 209: 'A6NFF2',\n 210: 'A6NFI3',\n 211: 'A6NFN9',\n 212: 'A6NFQ2',\n 213: 'A6NFQ7',\n 214: 'A6NFY4',\n 215: 'A6NGB0',\n 216: 'A6NGB9',\n 217: 'A6NGD5',\n 218: 'A6NGE4',\n 219: 'A6NGG8',\n 220: 'A6NGU5',\n 221: 'A6NGU7',\n 222: 'A6NGW2',\n 223: 'A6NH11',\n 224: 'A6NH52',\n 225: 'A6NHC0',\n 226: 'A6NHG4',\n 227: 'A6NHG9',\n 228: 'A6NHL2',\n 229: 'A6NHN6',\n 230: 'A6NHQ2',\n 231: 'A6NHR9',\n 232: 'A6NHT5',\n 233: 'A6NHY2',\n 234: 'A6NI47',\n 235: 'A6NI56',\n 236: 'A6NI61',\n 237: 'A6NI72',\n 238: 'A6NIE6',\n 239: 'A6NIJ5',\n 240: 'A6NIK2',\n 241: 'A6NIU2',\n 242: 'A6NIZ1',\n 243: 'A6NJB7',\n 244: 'A6NJG2',\n 245: 'A6NJI9',\n 246: 'A6NJJ6',\n 247: 'A6NJL1',\n 248: 'A6NJQ4',\n 249: 'A6NJR5',\n 250: 'A6NJZ3',\n 251: 'A6NJZ7',\n 252: 'A6NK02',\n 253: 'A6NK06',\n 254: 'A6NK58',\n 255: 'A6NK59',\n 256: 'A6NK89',\n 257: 'A6NKB5',\n 258: 'A6NKC0',\n 259: 'A6NKD9',\n 260: 'A6NKF2',\n 261: 'A6NKG5',\n 262: 'A6NKH3',\n 263: 'A6NKK0',\n 264: 'A6NKP2',\n 265: 'A6NKT7',\n 266: 'A6NKU9',\n 267: 'A6NL88',\n 268: 'A6NLC8',\n 269: 'A6NLU5',\n 270: 'A6NM11',\n 271: 'A6NM62',\n 272: 'A6NM76',\n 273: 'A6NMB9',\n 274: 'A6NMD2',\n 275: 'A6NMK7',\n 276: 'A6NMK8',\n 277: 'A6NMS7',\n 278: 'A6NMT0',\n 279: 'A6NMU1',\n 280: 'A6NMX2',\n 281: 'A6NMY6',\n 282: 'A6NMZ7',\n 283: 'A6NN06',\n 284: 'A6NN14',\n 285: 'A6NN73',\n 286: 'A6NN90',\n 287: 'A6NNH2',\n 288: 'A6NNJ1',\n 289: 'A6NNL0',\n 290: 'A6NNM3',\n 291: 'A6NNM8',\n 292: 'A6NNS2',\n 293: 'A6NNV3',\n 294: 'A6NNW6',\n 295: 'A6NNY8',\n 296: 'A6NNZ2',\n 297: 'A6PVC2',\n 298: 'A6PVI3',\n 299: 'A6PVS8',\n 300: 'A6QL63',\n 301: 'A6QL64',\n 302: 'A7E2F4',\n 303: 'A7E2V4',\n 304: 'A7E2Y1',\n 305: 'A7KAX9',\n 306: 'A7MBM2',\n 307: 'A7MCY6',\n 308: 'A7MD48',\n 309: 'A8CG34',\n 310: 'A8K0R7',\n 311: 'A8K0Z3',\n 312: 'A8K4G0',\n 313: 'A8K5M9',\n 314: 'A8K7I4',\n 315: 'A8K855',\n 316: 'A8K8P3',\n 317: 'A8MPX8',\n 318: 'A8MQ14',\n 319: 'A8MQB3',\n 320: 'A8MQT2',\n 321: 'A8MT19',\n 322: 'A8MT66',\n 323: 'A8MTI9',\n 324: 'A8MTJ3',\n 325: 'A8MTL9',\n 326: 'A8MUP6',\n 327: 'A8MUU1',\n 328: 'A8MV23',\n 329: 'A8MV24',\n 330: 'A8MV81',\n 331: 'A8MVJ9',\n 332: 'A8MVM7',\n 333: 'A8MVU1',\n 334: 'A8MVW0',\n 335: 'A8MVX0',\n 336: 'A8MW92',\n 337: 'A8MW95',\n 338: 'A8MW99',\n 339: 'A8MWA6',\n 340: 'A8MWE9',\n 341: 'A8MWX3',\n 342: 'A8MWY0',\n 343: 'A8MX19',\n 344: 'A8MX76',\n 345: 'A8MXE2',\n 346: 'A8MXJ8',\n 347: 'A8MXV4',\n 348: 'A8MXZ1',\n 349: 'A8MYA2',\n 350: 'A8MYB1',\n 351: 'A8MYJ7',\n 352: 'A8MYP8',\n 353: 'A8MYU2',\n 354: 'A8MYV0',\n 355: 'A8MZG2',\n 356: 'A8TX70',\n 357: 'A9QM74',\n 358: 'A9YTQ3',\n 359: 'A9Z1Z3',\n 360: 'B0FP48',\n 361: 'B0I1T2',\n 362: 'B1AH88',\n 363: 'B1AJZ9',\n 364: 'B1AK53',\n 365: 'B1AKI9',\n 366: 'B1AL46',\n 367: 'B1ANS9',\n 368: 'B2RC85',\n 369: 'B2RD01',\n 370: 'B2RN74',\n 371: 'B2RPK0',\n 372: 'B2RTY4',\n 373: 'B2RU33',\n 374: 'B2RXF0',\n 375: 'B2RXH2',\n 376: 'B2RXH8',\n 377: 'B3KS81',\n 378: 'B4DH59',\n 379: 'B4DZS4',\n 380: 'B4E2M5',\n 381: 'B5MCN3',\n 382: 'B5MCY1',\n 383: 'B5MD39',\n 384: 'B5ME19',\n 385: 'B6SEH8',\n 386: 'B6SEH9',\n 387: 'B7Z368',\n 388: 'B7Z6K7',\n 389: 'B7ZW38',\n 390: 'B9A064',\n 391: 'C0HLS1',\n 392: 'C0HLV8',\n 393: 'C4AMC7',\n 394: 'C9J1S8',\n 395: 'C9J3V5',\n 396: 'C9JE40',\n 397: 'C9JH25',\n 398: 'C9JLR9',\n 399: 'C9JN71',\n 400: 'C9JPN9',\n 401: 'C9JRZ8',\n 402: 'C9JTQ0',\n 403: 'D6RA61',\n 404: 'D6RCP7',\n 405: 'D6RIA3',\n 406: 'E2RYF6',\n 407: 'E2RYF7',\n 408: 'E5RIL1',\n 409: 'E5RJM6',\n 410: 'E7EW31',\n 411: 'E9PAV3',\n 412: 'F2Z3M2',\n 413: 'F5H284',\n 414: 'F5H4B4',\n 415: 'F8W1W9',\n 416: 'F8WCM5',\n 417: 'G2XKQ0',\n 418: 'G9CGD6',\n 419: 'H0UI37',\n 420: 'H3BPF8',\n 421: 'H3BPM6',\n 422: 'H3BQB6',\n 423: 'H3BQW9',\n 424: 'H3BUK9',\n 425: 'H7BZ55',\n 426: 'H7C350',\n 427: 'I0J062',\n 428: 'I6L899',\n 429: 'M0QZC1',\n 430: 'M0R2J8',\n 431: 'O00110',\n 432: 'O00116',\n 433: 'O00139',\n 434: 'O00142',\n 435: 'O00148',\n 436: 'O00151',\n 437: 'O00154',\n 438: 'O00155',\n 439: 'O00159',\n 440: 'O00160',\n 441: 'O00161',\n 442: 'O00165',\n 443: 'O00170',\n 444: 'O00178',\n 445: 'O00182',\n 446: 'O00186',\n 447: 'O00187',\n 448: 'O00192',\n 449: 'O00203',\n 450: 'O00206',\n 451: 'O00212',\n 452: 'O00213',\n 453: 'O00214',\n 454: 'O00217',\n 455: 'O00219',\n 456: 'O00220',\n 457: 'O00221',\n 458: 'O00222',\n 459: 'O00231',\n 460: 'O00232',\n 461: 'O00233',\n 462: 'O00257',\n 463: 'O00258',\n 464: 'O00264',\n 465: 'O00267',\n 466: 'O00268',\n 467: 'O00273',\n 468: 'O00291',\n 469: 'O00292',\n 470: 'O00294',\n 471: 'O00295',\n 472: 'O00299',\n 473: 'O00303',\n 474: 'O00308',\n 475: 'O00311',\n 476: 'O00327',\n 477: 'O00329',\n 478: 'O00330',\n 479: 'O00338',\n 480: 'O00339',\n 481: 'O00370',\n 482: 'O00391',\n 483: 'O00400',\n 484: 'O00401',\n 485: 'O00408',\n 486: 'O00409',\n 487: 'O00410',\n 488: 'O00411',\n 489: 'O00421',\n 490: 'O00429',\n 491: 'O00442',\n 492: 'O00443',\n 493: 'O00444',\n 494: 'O00451',\n 495: 'O00459',\n 496: 'O00461',\n 497: 'O00463',\n 498: 'O00468',\n 499: 'O00469',\n 500: 'O00471',\n 501: 'O00472',\n 502: 'O00478',\n 503: 'O00481',\n 504: 'O00483',\n 505: 'O00487',\n 506: 'O00488',\n 507: 'O00499',\n 508: 'O00501',\n 509: 'O00505',\n 510: 'O00506',\n 511: 'O00507',\n 512: 'O00512',\n 513: 'O00515',\n 514: 'O00533',\n 515: 'O00534',\n 516: 'O00548',\n 517: 'O00555',\n 518: 'O00560',\n 519: 'O00562',\n 520: 'O00566',\n 521: 'O00567',\n 522: 'O00571',\n 523: 'O00602',\n 524: 'O00628',\n 525: 'O00629',\n 526: 'O00635',\n 527: 'O00716',\n 528: 'O00750',\n 529: 'O00754',\n 530: 'O00755',\n 531: 'O00757',\n 532: 'O00762',\n 533: 'O00763',\n 534: 'O00764',\n 535: 'O00767',\n 536: 'O14490',\n 537: 'O14492',\n 538: 'O14497',\n 539: 'O14503',\n 540: 'O14511',\n 541: 'O14513',\n 542: 'O14514',\n 543: 'O14522',\n 544: 'O14525',\n 545: 'O14526',\n 546: 'O14529',\n 547: 'O14530',\n 548: 'O14559',\n 549: 'O14562',\n 550: 'O14578',\n 551: 'O14579',\n 552: 'O14594',\n 553: 'O14607',\n 554: 'O14617',\n 555: 'O14618',\n 556: 'O14628',\n 557: 'O14639',\n 558: 'O14640',\n 559: 'O14646',\n 560: 'O14647',\n 561: 'O14653',\n 562: 'O14654',\n 563: 'O14656',\n 564: 'O14657',\n 565: 'O14672',\n 566: 'O14682',\n 567: 'O14683',\n 568: 'O14686',\n 569: 'O14709',\n 570: 'O14715',\n 571: 'O14727',\n 572: 'O14730',\n 573: 'O14732',\n 574: 'O14737',\n 575: 'O14745',\n 576: 'O14746',\n 577: 'O14756',\n 578: 'O14763',\n 579: 'O14773',\n 580: 'O14775',\n 581: 'O14776',\n 582: 'O14782',\n 583: 'O14786',\n 584: 'O14787',\n 585: 'O14791',\n 586: 'O14793',\n 587: 'O14795',\n 588: 'O14802',\n 589: 'O14807',\n 590: 'O14815',\n 591: 'O14818',\n 592: 'O14827',\n 593: 'O14828',\n 594: 'O14829',\n 595: 'O14830',\n 596: 'O14832',\n 597: 'O14841',\n 598: 'O14867',\n 599: 'O14874',\n 600: 'O14879',\n 601: 'O14880',\n 602: 'O14896',\n 603: 'O14901',\n 604: 'O14908',\n 605: 'O14910',\n 606: 'O14917',\n 607: 'O14920',\n 608: 'O14924',\n 609: 'O14925',\n 610: 'O14926',\n 611: 'O14929',\n 612: 'O14931',\n 613: 'O14933',\n 614: 'O14936',\n 615: 'O14939',\n 616: 'O14948',\n 617: 'O14949',\n 618: 'O14950',\n 619: 'O14957',\n 620: 'O14964',\n 621: 'O14965',\n 622: 'O14966',\n 623: 'O14967',\n 624: 'O14972',\n 625: 'O14974',\n 626: 'O14976',\n 627: 'O14977',\n 628: 'O14978',\n 629: 'O14979',\n 630: 'O14980',\n 631: 'O14981',\n 632: 'O14983',\n 633: 'O14990',\n 634: 'O15013',\n 635: 'O15014',\n 636: 'O15015',\n 637: 'O15016',\n 638: 'O15018',\n 639: 'O15020',\n 640: 'O15021',\n 641: 'O15027',\n 642: 'O15031',\n 643: 'O15033',\n 644: 'O15034',\n 645: 'O15037',\n 646: 'O15042',\n 647: 'O15050',\n 648: 'O15054',\n 649: 'O15055',\n 650: 'O15056',\n 651: 'O15060',\n 652: 'O15061',\n 653: 'O15063',\n 654: 'O15066',\n 655: 'O15067',\n 656: 'O15068',\n 657: 'O15072',\n 658: 'O15078',\n 659: 'O15083',\n 660: 'O15084',\n 661: 'O15085',\n 662: 'O15090',\n 663: 'O15091',\n 664: 'O15111',\n 665: 'O15116',\n 666: 'O15117',\n 667: 'O15118',\n 668: 'O15119',\n 669: 'O15120',\n 670: 'O15123',\n 671: 'O15131',\n 672: 'O15143',\n 673: 'O15144',\n 674: 'O15145',\n 675: 'O15146',\n 676: 'O15151',\n 677: 'O15160',\n 678: 'O15162',\n 679: 'O15164',\n 680: 'O15165',\n 681: 'O15169',\n 682: 'O15173',\n 683: 'O15195',\n 684: 'O15197',\n 685: 'O15204',\n 686: 'O15209',\n 687: 'O15211',\n 688: 'O15212',\n 689: 'O15213',\n 690: 'O15218',\n 691: 'O15226',\n 692: 'O15228',\n 693: 'O15230',\n 694: 'O15231',\n 695: 'O15239',\n 696: 'O15240',\n 697: 'O15254',\n 698: 'O15255',\n 699: 'O15260',\n 700: 'O15264',\n 701: 'O15265',\n 702: 'O15269',\n 703: 'O15270',\n 704: 'O15294',\n 705: 'O15296',\n 706: 'O15297',\n 707: 'O15303',\n 708: 'O15305',\n 709: 'O15321',\n 710: 'O15344',\n 711: 'O15350',\n 712: 'O15353',\n 713: 'O15354',\n 714: 'O15355',\n 715: 'O15357',\n 716: 'O15360',\n 717: 'O15370',\n 718: 'O15371',\n 719: 'O15372',\n 720: 'O15381',\n 721: 'O15382',\n 722: 'O15389',\n 723: 'O15394',\n 724: 'O15397',\n 725: 'O15399',\n 726: 'O15400',\n 727: 'O15403',\n 728: 'O15405',\n 729: 'O15409',\n 730: 'O15417',\n 731: 'O15427',\n 732: 'O15438',\n 733: 'O15439',\n 734: 'O15446',\n 735: 'O15455',\n 736: 'O15457',\n 737: 'O15460',\n 738: 'O15466',\n 739: 'O15467',\n 740: 'O15480',\n 741: 'O15481',\n 742: 'O15492',\n 743: 'O15498',\n 744: 'O15504',\n 745: 'O15511',\n 746: 'O15514',\n 747: 'O15516',\n 748: 'O15519',\n 749: 'O15523',\n 750: 'O15530',\n 751: 'O15533',\n 752: 'O15534',\n 753: 'O15539',\n 754: 'O15541',\n 755: 'O15547',\n 756: 'O15550',\n 757: 'O15551',\n 758: 'O15553',\n 759: 'O43143',\n 760: 'O43149',\n 761: 'O43150',\n 762: 'O43151',\n 763: 'O43155',\n 764: 'O43159',\n 765: 'O43164',\n 766: 'O43166',\n 767: 'O43169',\n 768: 'O43172',\n 769: 'O43175',\n 770: 'O43182',\n 771: 'O43184',\n 772: 'O43187',\n 773: 'O43189',\n 774: 'O43196',\n 775: 'O43236',\n 776: 'O43237',\n 777: 'O43240',\n 778: 'O43242',\n 779: 'O43252',\n 780: 'O43264',\n 781: 'O43278',\n 782: 'O43283',\n 783: 'O43286',\n 784: 'O43290',\n 785: 'O43292',\n 786: 'O43294',\n 787: 'O43295',\n 788: 'O43296',\n 789: 'O43299',\n 790: 'O43301',\n 791: 'O43303',\n 792: 'O43304',\n 793: 'O43306',\n 794: 'O43307',\n 795: 'O43309',\n 796: 'O43310',\n 797: 'O43314',\n 798: 'O43323',\n 799: 'O43324',\n 800: 'O43345',\n 801: 'O43353',\n 802: 'O43361',\n 803: 'O43379',\n 804: 'O43390',\n 805: 'O43395',\n 806: 'O43396',\n 807: 'O43399',\n 808: 'O43405',\n 809: 'O43423',\n 810: 'O43424',\n 811: 'O43426',\n 812: 'O43432',\n 813: 'O43451',\n 814: 'O43488',\n 815: 'O43490',\n 816: 'O43491',\n 817: 'O43497',\n 818: 'O43504',\n 819: 'O43506',\n 820: 'O43511',\n 821: 'O43516',\n 822: 'O43520',\n 823: 'O43525',\n 824: 'O43526',\n 825: 'O43529',\n 826: 'O43542',\n 827: 'O43559',\n 828: 'O43566',\n 829: 'O43567',\n 830: 'O43572',\n 831: 'O43586',\n 832: 'O43592',\n 833: 'O43593',\n 834: 'O43598',\n 835: 'O43609',\n 836: 'O43615',\n 837: 'O43617',\n 838: 'O43663',\n 839: 'O43665',\n 840: 'O43670',\n 841: 'O43674',\n 842: 'O43678',\n 843: 'O43681',\n 844: 'O43683',\n 845: 'O43684',\n 846: 'O43687',\n 847: 'O43692',\n 848: 'O43704',\n 849: 'O43707',\n 850: 'O43708',\n 851: 'O43709',\n 852: 'O43711',\n 853: 'O43715',\n 854: 'O43716',\n 855: 'O43719',\n 856: 'O43734',\n 857: 'O43736',\n 858: 'O43739',\n 859: 'O43747',\n 860: 'O43752',\n 861: 'O43760',\n 862: 'O43765',\n 863: 'O43766',\n 864: 'O43772',\n 865: 'O43776',\n 866: 'O43781',\n 867: 'O43790',\n 868: 'O43791',\n 869: 'O43795',\n 870: 'O43805',\n 871: 'O43809',\n 872: 'O43813',\n 873: 'O43815',\n 874: 'O43818',\n 875: 'O43823',\n 876: 'O43824',\n 877: 'O43837',\n 878: 'O43847',\n 879: 'O43852',\n 880: 'O43854',\n 881: 'O43861',\n 882: 'O43865',\n 883: 'O43866',\n 884: 'O43868',\n 885: 'O43889',\n 886: 'O43895',\n 887: 'O43896',\n 888: 'O43897',\n 889: 'O43900',\n 890: 'O43903',\n 891: 'O43909',\n 892: 'O43913',\n 893: 'O43914',\n 894: 'O43915',\n 895: 'O43916',\n 896: 'O43929',\n 897: 'O43933',\n 898: 'O60216',\n 899: 'O60218',\n 900: 'O60220',\n 901: 'O60229',\n 902: 'O60231',\n 903: 'O60232',\n 904: 'O60234',\n 905: 'O60237',\n 906: 'O60240',\n 907: 'O60241',\n 908: 'O60242',\n 909: 'O60244',\n 910: 'O60248',\n 911: 'O60256',\n 912: 'O60260',\n 913: 'O60264',\n 914: 'O60266',\n 915: 'O60268',\n 916: 'O60269',\n 917: 'O60271',\n 918: 'O60279',\n 919: 'O60281',\n 920: 'O60282',\n 921: 'O60284',\n 922: 'O60285',\n 923: 'O60287',\n 924: 'O60290',\n 925: 'O60292',\n 926: 'O60293',\n 927: 'O60296',\n 928: 'O60299',\n 929: 'O60303',\n 930: 'O60307',\n 931: 'O60308',\n 932: 'O60309',\n 933: 'O60312',\n 934: 'O60313',\n 935: 'O60315',\n 936: 'O60318',\n 937: 'O60330',\n 938: 'O60333',\n 939: 'O60337',\n 940: 'O60341',\n 941: 'O60343',\n 942: 'O60346',\n 943: 'O60347',\n 944: 'O60353',\n 945: 'O60359',\n 946: 'O60361',\n 947: 'O60391',\n 948: 'O60393',\n 949: 'O60403',\n 950: 'O60412',\n 951: 'O60423',\n 952: 'O60427',\n 953: 'O60437',\n 954: 'O60443',\n 955: 'O60447',\n 956: 'O60449',\n 957: 'O60462',\n 958: 'O60469',\n 959: 'O60477',\n 960: 'O60486',\n 961: 'O60488',\n 962: 'O60493',\n 963: 'O60494',\n 964: 'O60496',\n 965: 'O60499',\n 966: 'O60500',\n 967: 'O60502',\n 968: 'O60504',\n 969: 'O60506',\n 970: 'O60508',\n 971: 'O60518',\n 972: 'O60522',\n 973: 'O60547',\n 974: 'O60551',\n 975: 'O60568',\n 976: 'O60603',\n 977: 'O60610',\n 978: 'O60613',\n 979: 'O60641',\n 980: 'O60645',\n 981: 'O60656',\n 982: 'O60663',\n 983: 'O60664',\n 984: 'O60673',\n 985: 'O60674',\n 986: 'O60678',\n 987: 'O60682',\n 988: 'O60684',\n 989: 'O60701',\n 990: 'O60704',\n 991: 'O60706',\n 992: 'O60711',\n 993: 'O60716',\n 994: 'O60721',\n 995: 'O60732',\n 996: 'O60733',\n 997: 'O60749',\n 998: 'O60760',\n 999: 'O60762',\n ...}"
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the dictionary mapping from global node index to original protein accession\n",
    "mapping = data_batch.mapping\n",
    "reversed_mapping = {v: k for k, v in mapping.items()}\n",
    "reversed_mapping"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-04T18:32:27.629316Z",
     "start_time": "2023-10-04T18:32:27.601928Z"
    }
   },
   "id": "19e2f1e17750bb8d"
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "outputs": [
    {
     "data": {
      "text/plain": "NeighborLoader()"
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datamodule.loaders[1]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-04T18:14:36.169013Z",
     "start_time": "2023-10-04T18:14:36.139823Z"
    }
   },
   "id": "552dce2c699be9d5"
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "outputs": [],
   "source": [
    "# check why it is full-size batch and need to have original ID in the dataset\n",
    "# how to retrieve original ID\n",
    "model.eval()\n",
    "accession = []\n",
    "all_pred_prob = []\n",
    "all_soft_label = []\n",
    "all_raw_prob = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in datamodule.loaders[1]:\n",
    "        # batch = batch.to(cfg.accelerator)\n",
    "        \n",
    "        # for each batch, only use test nodes in the original mini-batch nodes\n",
    "        batch_mask = torch.cat([torch.ones(batch.batch_size), torch.zeros(len(batch.y) - batch.batch_size)], dim=0)\n",
    "        batch_mask = batch_mask.bool()\n",
    "        mask = batch_mask & batch.test_mask\n",
    "        raw_prob = batch.x[:, 0][mask]\n",
    "        \n",
    "        logits, true = model(batch)\n",
    "\n",
    "        # for each batch, only use test nodes in the original mini-batch nodes\n",
    "        global_node_idx = batch.n_id[mask]\n",
    "        original_id = [reversed_mapping[key] for key in global_node_idx.tolist()]\n",
    "        \n",
    "        logits, true = logits[mask], true[mask]\n",
    "        logits.squeeze_(-1)\n",
    "        pred_prob = torch.nn.functional.sigmoid(logits)\n",
    "        \n",
    "        \n",
    "        \n",
    "        accession = accession + original_id\n",
    "        all_raw_prob += raw_prob.tolist()\n",
    "        all_pred_prob += pred_prob.tolist()\n",
    "        all_soft_label += true.tolist()\n",
    "        # print(original_id)\n",
    "        # print(pred_prob)\n",
    "        # print(true)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-04T19:13:54.648577Z",
     "start_time": "2023-10-04T19:13:21.245691Z"
    }
   },
   "id": "986b5921dd2bb4b5"
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "outputs": [
    {
     "data": {
      "text/plain": "       accession  raw_prob  pred_prob  soft_label\n0     A0A087X0M5  0.976280   0.983320    0.979157\n1     A0A087X1C5  0.243009   0.675054    0.784043\n2     A0A0A6YYL3  0.341797   0.697359    0.855166\n3     A0A0B4J1V2  0.572661   0.776625    0.979623\n4     A0A0B4J1X8  0.999882   0.983741    0.999882\n...          ...       ...        ...         ...\n4080      Q9BXW3  0.000000   0.729058    0.982459\n4081      Q9HAA7  0.000000   0.570404    0.000000\n4082      Q9UF83  0.000000   0.570404    0.184923\n4083      Q9Y6Z2  0.000000   0.583879    0.000000\n4084      X6R8R1  0.000000   0.570404    0.769844\n\n[4085 rows x 4 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>accession</th>\n      <th>raw_prob</th>\n      <th>pred_prob</th>\n      <th>soft_label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>A0A087X0M5</td>\n      <td>0.976280</td>\n      <td>0.983320</td>\n      <td>0.979157</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>A0A087X1C5</td>\n      <td>0.243009</td>\n      <td>0.675054</td>\n      <td>0.784043</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>A0A0A6YYL3</td>\n      <td>0.341797</td>\n      <td>0.697359</td>\n      <td>0.855166</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>A0A0B4J1V2</td>\n      <td>0.572661</td>\n      <td>0.776625</td>\n      <td>0.979623</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>A0A0B4J1X8</td>\n      <td>0.999882</td>\n      <td>0.983741</td>\n      <td>0.999882</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>4080</th>\n      <td>Q9BXW3</td>\n      <td>0.000000</td>\n      <td>0.729058</td>\n      <td>0.982459</td>\n    </tr>\n    <tr>\n      <th>4081</th>\n      <td>Q9HAA7</td>\n      <td>0.000000</td>\n      <td>0.570404</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>4082</th>\n      <td>Q9UF83</td>\n      <td>0.000000</td>\n      <td>0.570404</td>\n      <td>0.184923</td>\n    </tr>\n    <tr>\n      <th>4083</th>\n      <td>Q9Y6Z2</td>\n      <td>0.000000</td>\n      <td>0.583879</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>4084</th>\n      <td>X6R8R1</td>\n      <td>0.000000</td>\n      <td>0.570404</td>\n      <td>0.769844</td>\n    </tr>\n  </tbody>\n</table>\n<p>4085 rows × 4 columns</p>\n</div>"
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame({'accession': accession, 'raw_prob': all_raw_prob, 'pred_prob': all_pred_prob, 'soft_label': all_soft_label})"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-04T19:13:54.690205Z",
     "start_time": "2023-10-04T19:13:54.668121Z"
    }
   },
   "id": "f81bba827ee3eb67"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "46598ba37f321505"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
